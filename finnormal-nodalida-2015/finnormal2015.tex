%
% File nodalida2015.tex
%
% Contact beata.megyesi@lingfil.uu.se
%
% Based on the instruction file for EACL 2014
% which in turn was based on the instruction files for previous 
% ACL and EACL conferences.

\documentclass[11pt]{article}
\usepackage{nodalida2015}
\usepackage{expex}
%\usepackage{times}
\usepackage{mathptmx}
%\usepackage{txfonts}
\usepackage{url}
\usepackage{multirow}
\usepackage[small,bf]{caption}
\usepackage{latexsym}
\special{papersize=210mm,297mm} % to avoid having to use "-t a4" with dvips 
%\setlength\titlebox{6.5cm}  % You can expand the title box if you really have to

\title{Automatic conversion of colloquial Finnish to standard Finnish}

\author{}
%
%Francis M. Tyers\\
%  UiT Norgga \'{a}rktala\v{s} universitehta, \\
%  N-9015 Norway \\
%  {\tt francis.tyers@uit.no} \\\And
%  Inari Listenmaa\\
%  Chalmers tekniska h\"{o}gskola, \\
%  Sweden \\
%  {\tt inari@chalmers.se} \\}
%
\date{}

\begin{document}
\maketitle
\begin{abstract}
  This paper presents an unsupervised method for converting between colloquial Finnish
  and standard Finnish. The method relies upon a small number of orthographical rules
  combined with a large language model of standard Finnish for ranking the possible 
  conversions. Aside from this contribution, the paper also presents an evaluation
  corpus consisting of aligned sentences in colloquial Finnish, orthographically-standardised
  colloquial Finnish and standard Finnish. The methods we present outperforms the baseline
  of simply treating colloquial Finnish as standard Finnish and offers promise for the adaptation
  of language-technology tools created for standard Finnish to colloquial Finnish. To this end
  the paper also presents preliminary results which show promise for using normalisation in 
  the machine translation task.
\end{abstract}

\section{Introduction}

Most language technology tools are designed or trained based on standard language 
forms, where they exist. The application of these tools to non-standard
language can cause a substantial decrease in quality. For example in machine translation,
parsing and part-of-speech tagging \cite{eisenstein2013}. Non-standard language can 
have different orthographic conventions, along with different morphology, syntax and stylistics.

For language-technology researchers working on non-standard forms of language, there are 
two clear options: either create new tools to process non-standard text,
  or create tools to preprocess non-standard text, standardising it to be subsequently processed
 by existing tools.

This paper evaluates a number of methods for converting colloquial Finnish to 
standard Finnish and describes a parallel corpus for evaluation.

\section{Related work}

There are a number of areas of research related to the task of text normalisation. Text
proofing tools, such as spelling and grammar checkers \cite{kukich1992} can be used to encourage adherence
to particular orthographic or grammatical norms. Accent and diacritic restoration --- for example in \newcite{scannell2011} --- is similar
in that it aims to bring text closer to standard orthography in order to facilitate treatment by 
automatic tools. Another related area is machine translation between different written norms of 
the same language. For example between Norwegian Bokm\aa{}l and Norwegian Nynorsk \cite{unhammer2009}.

\newcite{scannell2014} presents a method for normalising pre-standardised text in Irish to 
the modern standard. The method relies on a translation model consisting of word-to-word 
correspondences in addition to spelling rules. Each word-to-word mapping has the same
conditional probability and a penalty is assigned to each spelling rule application. Decoding
works by processing the source sentence word-for-word left-to-right, keeping track of the 
possible `hypothesis' translations and their probabilities, and when the end of 
sentence is reached, the most probable is output.

\subsection{Colloquial Finnish}


\newcite{viinikka2013} describe the common meaning of the terms colloquial (\emph{puhekieli}) and standard (\emph{yleiskieli} or \emph{kirjakieli}) Finnish: standard language is unified in morphology and vocabulary, following the regulations of a language board; colloquial language shows local and idiolectal variation, and has structures that are characteristic to spoken variety,  such as discourse particles and incomplete clauses. 

% Colloquial Finnish differs from standard Finnish in some key features: 

% Morphology shows dialectal variation, shortening and merging of morphemes, e.g. \emph{en min\"{a}} `not I' $\rightarrow$ \emph{emm\"{a}} (`I don't').

% Syntax: due to the spontaneous nature of colloquial language, syntactic structures are common for spoken language. 
%Prototypically, colloquial language is spoken and spontaneous, and standard is written, planned and structured. 

We illustrate the differences with the following example from our data set. Sentence 1 is the original colloquial version. The gloss shows the actual word-by-word translation, and the translation shows similar style and register in English.

\ex
\begingl
\gla seiskakin oli vaan silleen et fonotaksista p\"{a}\"{a}ttelin //
\glb seven-{\sc also} was just like.that that phonotactics.{\sc ela} I.deduced //
\glft `also the seventh, it was like, I just deduced it from phonotactics' //
\endgl
\xe


For the normalised version,\footnote{The normalised version is converted orthographically and lexically, but not syntactically or stylistically.} we changed only morphology and vocabulary. On the lexical level, the word \emph{seiska} `number 7' is colloquial style, and in the standard translation it is replaced by the ordinal \emph{seitsem\"{a}s} `seventh'.  Other changes in the normalised version are common morphological or phonological, phenomena, such as reducing the diphthong in \emph{vain} $\rightarrow$ \emph{vaan} or shortening in  \emph{ett\"{a}} $\rightarrow$ \emph{et}. The original sentence and the normalised translation are shown below, aligned word by word.

\ex
\begingl
\gla seiskakin oli vaan silleen et fonotaksista p\"{a}\"{a}ttelin //
\glb seitsem\"{a}skin oli vain sill\"{a}\#lailla ett\"{a} fonotaksista p\"{a}\"{a}ttelin //
%\glb seventh-{\sc also} was just like.that that phonotactics.{\sc ela} I.deduced //
% \glft `also the seventh, it was like, I just deduced it from phonotactics' //
\endgl
\xe

 The syntactic structure of the original sentence is markedly spoken; the word \emph{seiska} is topicalised, and the main information ``deduced from phonotactics'' is in a subordinate clause. 
The translation into standard Finnish is shorter and more precise, leaving just the main information.

\ex
\begingl
\gla p\"{a}\"{a}ttelin seitsem\"{a}nnenkin fonotaksista //
\glb I.deduced seventh-{\sc also} phonotactics.{\sc ela} //
\glft `I deduced also the seventh from phonotactics' //
\endgl
\xe




% ``Yleens\"{a} kirjakieli ymm\"{a}rret\"{a}\"{a}n samaksi kuin yleiskieli: kielenhuollon suositusten mukaiseksi standardoiduksi kieleksi, jonka sanasto on yleistajuista. Puhekieli puolestaan miellet\"{a}\"{a}n kirjakielt\"{a} arkisemmaksi ja tyylilt\"{a}\"{a}n vapaamuotoisemmaksi kielimuodoksi, jonka ei tarvitse noudattaa kirjakielen s\"{a}\"{a}ntöj\"{a} (esim. mie, h\"{a}nen koira, me kirjotetaan vs. min\"{a}, h\"{a}nen koiransa, me kirjoitamme).''


\section{Corpus}

\begin{table}
  \centering
 \begin{tabular}{|l|r|r|r|}
    \hline
    \multirow{2}{*}{\textbf{Section}} & \multicolumn{3}{|c|}{\textbf{Tokens}} \\\cline{2-4}
                                      & \texttt{train} & \texttt{test} & \texttt{dev} \\
    \hline
    Colloquial                           & 5,103 & 1,012 & 1,003 \\ 
    Normalised                           & 5,105 & 1,012 & 1,003 \\ 
    Standardised                         & 4,982 & 991 & 1,000 \\
    \hline
 \end{tabular} 
  \caption{Statistics on sentences from the parallel corpus.}
  \label{table:corpsize}
\end{table}

\begin{table*}
  \centering
  \begin{tabular}{|l|l|l|}
  \hline
  \textbf{Colloquial} & \textbf{Normalised} & \textbf{Standardised} \\
  \hline
  tai emm\"{a} tii\"{a} olikse erikseen & tai en\#min\"{a} tied\"{a} oliko\#se erikseen & tai en min\"{a} tied\"{a} oliko erikseen \\
  joku nuorisoalennus                             & jokin nuorisoalennus & nuorisoalennus \\
  \hline
   toistaseks tullu        & toistaiseksi tullut  & toistaiseksi on tullut  \\
   kaks kysymyst\"{a}       & kaksi kysymyst\"{a} & kaksi kysymyst\"{a} \\
  \hline
  ja sit 2009 just ennenku & ja sitten 2009 juuri ennen\#kuin  & ja sitten 2009 juuri ennen kuin  \\ 
menin Japaniin & menin Japaniin & menin Japaniin
 \\
  \hline
  \end{tabular}
  \caption{Example sentences from the parallel corpus. The \texttt{\#} mark represents a missing
    word boundary.}
  \label{table:corpexample}
\end{table*}

Our evaluation corpus was created by manually translating texts in colloquial Finnish
to standard Finnish.\footnote{The corpus is freely available and published under the 
CreativeCommons {\sc cc-by-sa} 3.0 licence.} The texts were extracts from internet 
relay chat (IRC) conversations. We performed the conversion process in two steps, the first
step involved simple orthographic normalisation, for 
example \emph{oon} $\rightarrow$ \emph{olen} `I am'. Syntactic and stylistic conversions 
were not applied at this stage. The second conversion step normalised the text
both orthographically and syntactically/stylistically. Table~\ref{table:corpexample} presents
an excerpt from each of the three parts of the corpus.

The corpus was split into three parts, testing, development and training. The testing
and development portions contain approximately 1,000 words each, with the remaining approximately 5,000 words for training
supervised models.\footnote{The corpus is split into 14 files of 500 words each. Files 01--02 
  were used for development; 03--04 for testing and 05--14 for training.} Table~\ref{table:corpsize} gives statistics on the number of words in each section.

\section{Experiments}

\subsection{Unsupervised normalisation}

For the unsupervised normalisation we applied a set of regular-expression based 
replace rules to the input text to produce all the possible candidate sentences 
in standard Finnish and then used a target-language model to rank the possible 
candidates. The candidate with the highest rank was selected as the normalised sentence.
For the target-language model we used the Finnish side of the English--Finnish EuroParl
parallel corpus \cite{koehn2005}.

We developed two sets of rules for the unsupervised normalisation approach:

\begin{itemize}
  \item \texttt{rules-1}: 273 rules from \newcite{karlsson2008}'s grammar of Finnish (\S95--97). The 
    rules took around one hour to implement.
  \item \texttt{rules-2}: 98 rules written by examining the development corpus, these rules also
    took approximately one hour to implement.
\end{itemize}

The rules included both simple one-to-one (`m\"{a}' $\rightarrow$ `min\"{a}') and one-to-many (`emm\"{a}' $\rightarrow$ `en min\"{a}') word correspondences,
and also regular expression substitutions which could match a prefix or a suffix (`(?+)nkaa' $\rightarrow$ `\textbackslash1n kanssa').

Table~\ref{table:unsup-trace} gives an example trace of the system on a simple sentence
using three replace rules.

\begin{table*}
  \centering
  \begin{tabular}{|l|l|r|l|}
    \hline
    \textbf{Input:} & \multicolumn{3}{l|}{M\"{a} oon Tomminkaa `I am with Tommi'.} \\
    \hline
    \multirow{2}{*}{Step 1}  & M\"{a} oon Tomminkaa & & apply rule 1: \\
                             & Min\"{a} oon Tomminkaa & & ~~~m\"{a} $\rightarrow$ min\"{a} \\
    \hline
    \multirow{2}{*}{Step 2}  & M\"{a} oon Tomminkaa & & apply rule 2: \\
                             & Min\"{a} oon Tomminkaa & & ~~~oon $\rightarrow$ olen \\
                             & M\"{a} olen Tomminkaa & & \\
                             & Min\"{a} olen Tomminkaa & & \\
    \hline
    \multirow{2}{*}{Step 3}  & M\"{a} oon Tomminkaa   & & apply rule 3:\\
                             & Min\"{a} oon Tomminkaa &  & ~~~(?+)nkaa $\rightarrow$ \textbackslash1n kanssa \\
                             & M\"{a} olen Tomminkaa  & &\\
                             & Min\"{a} olen Tomminkaa  & &\\
                             & M\"{a} oon Tommin kanssa  & &\\
                             & Min\"{a} oon Tommin kanssa  & &\\
                             & M\"{a} olen Tommin kanssa  & &\\
                             & Min\"{a} olen Tommin kanssa  & &\\
    \hline
    \multirow{2}{*}{Step 4} &  Min\"{a} olen Tommin kanssa & -4.5811 & rank candidates \\
                            &  Min\"{a} oon Tommin kanssa & -7.8174 & \\
                            &  M\"{a} olen Tommin kanssa & -8.0941 & \\
                            &  M\"{a} oon Tommin kanssa & -8.8651 & \\
                            &  Min\"{a} olen Tomminkaa & -9.2045 & \\
                            &  Min\"{a} oon Tomminkaa & -12.4408 & \\
                            &  M\"{a} olen Tomminkaa & -12.7176 & \\
                            &  M\"{a} oon Tomminkaa & -13.4885 & \\

    \hline
    \textbf{Output:} & \multicolumn{3}{l|}{Min\"{a} olen Tommin kanssa} \\
    \hline
  \end{tabular}
  \caption{Example trace of the unsupervised normalisation method. Rules are applied in order to each of 
     the possible candidate translations in turn. The candidates are then ranked using an $n$-gram language model 
     of standard Finnish and either an $n$-best list
     or the best candidate is output.}
  \label{table:unsup-trace}
\end{table*}

\subsection{Statistical machine translation}

The statistical-machine translation approaches were implemented using the 
Moses toolkit \cite{koehn2007}. The training set up was that used for
the baseline system in the WMT shared tasks
on machine translation.\footnote{\url{http://www.statmt.org/wmt11/baseline.html}}

The target-language model corpus, trained using KenLM \cite{heafield2011}, used was the same as in the unsupervised experiments.  

We trained models based on two approaches, the first being phrase-based machine translation (PBMT, \newcite{zens2002}) and the second on character-based machine translation (CBMT, \newcite{nakov2012}; \newcite{TiedemannEAMT2009}).

For both approaches we trained two systems, the first used the \emph{normalised}
part of the corpus as the target language; the second used the \emph{standardised} 
part of the corpus as the target language.

The idea behind this was that the \emph{normalised} part of the corpus would be closer
to the original colloquial text than the \emph{standardised} part, making it easier
to learn the alignment model. 

\subsubsection{Character-based}

\newcite{nakov2012} present a method of statistical machine translation on the character level between related languages that takes advantage of phrase-based machine translation architecture. The method relies on preprocessing the input and output by inserting spaces in between the characters of words, for example the string `m\"{a} meen Helsinkiin' would become `m \"{a} \$ m e e n \$ H e l s i n k i i n' with a unigram model, or `m\"{a} \"{a}\$ \$m me ee en n\$ \$H He el ls si in nk ki ii in' with a bigram model.

After preprocessing, the corpora are processed as with the phrase-based system, with the difference that the language model order is increased from 5 to 10-grams.

\subsection{End-to-end translation}

In order to evaluate how well the different normalisation strategies worked in 
combination with another language technology tool, we performed an end-to-end experiment
involving machine translation.
To evaluate this, we took the colloquial portion of the test corpus and manually 
translated it to English. For each of the best-performing systems we first passed
the colloquial text through, and then translated the output to English using
a widely-used online machine translation engine with Finnish to English. We compared
the output to translating the text to English without the standardiser. 

\section{Results}

\begin{table}
  \centering
  \begin{tabular}{|l|r|r|r|}
     \hline
    \textbf{System} & \textbf{PER} & \textbf{WER} & \textbf{BLEU} \\
     \hline
     Baseline & 46.12 & 48.04 & 26.31 \\
     \hline
     rules-1 & 38.27 & 41.19 & 32.65 \\
     rules-2 & \textbf{38.17} & \textbf{35.25} & \textbf{36.41} \\
     rules-c & 36.56 & 39.68 & 34.68 \\
     \hline
     {\sc cbmt}-cn & 43.09 & 48.34 & 33.55 \\
     {\sc cbmt}-cs & 46.22 & 52.27 & 29.21 \\
     {\sc pbmt}-cn & \textbf{28.05} & \textbf{35.42} & \textbf{48.37} \\
     {\sc pbmt}-cs & 27.95 & 36.13 & 46.76 \\
     \hline
  \end{tabular}
  \caption{Results for the normalisation task. The system \texttt{rules-c} is the combination
     of the rules in \texttt{rules-1} and \texttt{rules-2}. The figures in bold are the 
     best results for unsupervised and supervised methods.}
  \label{table:results-norm}
\end{table}

Tables~\ref{table:results-norm} and \ref{table:results-trad} present the results of the experiments. 

The baseline was made by calculating the metric scores between the standardised `reference' 
and the colloquial input. The results show that all conversion methods outperform the baseline.

Our unsupervised method performs similarly to the character-based machine translation systems. Both 
the character-based systems and the unsupervised system achieve around half of the performance of the 
supervised phrase-based system.

Out of the unsupervised systems, the set of rules which was created by examining the development corpus
outperforms both the set of rules from the grammar and the combined rules.

It is interesting to note that supervised systems trained on the normalised section of the corpus outperform
those trained on the standardised corpus. One explanation for this could be that the corpus size is small, so 
that the word alignments are not as reliable on the standardised corpus which is by nature not a word-for-word 
conversion.

\begin{table}
  \centering
  \begin{tabular}{|l|r|r|r|}
     \hline
    \textbf{System} & \textbf{PER} & \textbf{WER} & \textbf{BLEU} \\
     \hline
     Colloquial &  41.02  &  69.57  & 12.11 \\
     Normalised &  30.73  &  59.73  & 22.56 \\
     Standardised &  33.88  &  61.61  & 19.49 \\
     \hline
     rules-2 &  37.94  &  69.35  & 12.92 \\
     \hline
     {\sc cbmt}-cn &  65.59  &  86.25  & 13.06 \\
     {\sc pbmt}-cn &  \textbf{35.69}  &  \textbf{65.14}  & \textbf{17.75} \\
     \hline
  \end{tabular}
  \caption{Results for the Finnish to English translation task. The first three rows are the results 
    from translating the sections of the corpus.}
  \label{table:results-trad}
\end{table}

The systems for normalisation are able to improve out-of-vocabulary rates in 
many cases, most likely as the online statistical system that we used is trained
on more formal texts. Frequent contractions such as \emph{onks?} `is there?',
\emph{oo} `be.{\sc conneg}'\footnote{The word \emph{oo} is the negative form of the verb \emph{olla} `to be' in Finnish.} and \emph{vaa} `only' are found untranslated in the output, but 
are easily converted by the systems.

%! ooh mitä onks siellä lunta
%! mitä! Onko siellä lunta?
%ref: ooh what, is there snow?
%colloq: ooh what onks there snow
%book: what! Is there snow?
%pbmt: ooh what if there's snow
%rules: ooh what if there's snow

%! mä vaa protestoin et ei siinä mitää tavurajaa oo i:den välissä
%! minä vain protestoin, että ei siinä mitään tavurajaa ole i:den välissä
%ref: I was just protesting that there's no syllable break between the two i's
%colloq: I VAA you do not protest it makes no tavurajaa oo i: in between
%book: I just protest, that's not anything tavurajaa no i in between
%pbmt: I only protest that there is no tavurajaa in between the i-den
%rules: I VAA you do not protest it makes no tavurajaa no i in between

%! (kyse oli siis vaan jostain 3 rivistä loopin sisällä)
%! (kyse oli siis vain 3:sta rivistä loopin sisällä)
% ref: (it was only like 3 lines inside a loop)
% colloq: (it was, therefore, but for some three lines within the loop)
% book: (it was, therefore, only three to a row within a loop)
% pbmt: (it was, therefore, only some three-line within the loop)
% rules: (it was Siisi only some 3 lines of the loop inside)

\section{Future work}

Although a reasonable size for a test corpus, the corpus is still too small for 
wide-coverage experiments. We intend to expand the corpus size to at least 10,000
words. Another weakness of the corpus is that it contains text from a single author,
we would ideally like to add texts from other authors and other colloquial genres. Although
the challenge here is finding text that is both free of privacy issues and available
to release under a free/open-source licence.

As for the methods, we would like to follow \newcite{scannell2014} in incorporating
`translation' probabilities into our unsupervised normalisation model. Our current model relies 
exclusively on the target-language model probability, however some rules may be more
reliable or probable than others.

\section{Conclusions}

We have presented a parallel corpus of colloquial Finnish and standard Finnish --
to our knowledge the first of its kind -- and an evaluation of methods for 
converting colloquial Finnish to standard Finnish. 

We have shown that converting from colloquial Finnish to standard Finnish substantially
helps with the Finnish to English machine translation task.

\section*{Acknowledgments}

\textit{Removed for review}
%Joonas Kylm\"{a}l\"{a}

% If you use BibTeX with a bib file named eacl2014.bib, 
% you should add the following two lines:
\bibliographystyle{acl}
\bibliography{finnormal2015}

\end{document}
