==Introduction==

This article describes the work towards the development of a dependency treebank for Kazakh, a 
Turkic language spoken in Central Asia. 
Despite its status as a \emph{core} Turkic
language, little computational-linguistic research has been published on syntactic
parsing for Kazakh. 
A valuable resource in the study of syntactic parsing is 
a treebank---a corpus of parsed text containing gold-standard syntactic annotation. 

Freely available treebanks exist for many languages, such as large languages like Finnish (x,y)
and Polish (xxx) and smaller languages like Irish (zz). To our knowledge only one treebank
exists for another language, Turkish (yyy), which is unfortunately not freely available.

In building our treebank we take advantage of existing work done on tokenisation,
morphological analysis and part-of-speech tagging for Kazakh. We also take a pragmatic
and iterative view of development of the treebank, in line with recent work 
on cross-linguistic parsing with universal dependencies.

The remainder of the paper is organised as follows. Section~\ref{sec:back} gives some 
background linguistic information on Kazakh, and outlines some special challenges in 
parsing Kazakh. In Section~\ref{sec:method} we describe the corpus itself and methodology
used in annotating it. Section~\ref{sec:annotation} gives a sketch of some decisions
we have made with respect to annotation guidelines, referring back to the discussion in 
Section~\ref{sec:back}. For reasons of space, these guidelines are not complete, but 
present a subset of guidelines which are of particular interest. A small experiment
in statistical dependency parsing using the corpus is presented in Section~\ref{sec:eval},
and in Sections~\ref{sec:future} and \ref{sec:conclusions} we give perspectives
for future work and some concluding remarks.

==Evaluation==

In order to test the utility of the treebank in a real-world setting, we trained
and evaluated a number of models using the popular MaltParser tool \citep{nivre07}.
MaltParser is a toolkit for data-driven dependency parsing, it can learn a parsing
model from treebank data and apply this model to parse unseen sentences. The parser
has a large number of options and parameters that need to be optimised. 
To select the best parser configuration we relied on 
MaltOptimiser \citep{ballesteros15}. The optimiser was run separately for each of 
the model configurations.

As the treebank takes advantage of the new tokenisation standards in the CoNLL-U format,
and MaltParser only supports CoNLL-X, certain transformations were needed to perform 
the experiments. The corpus was flattened with conjoined tokens receiving a dummy 
surface form. The converted corpus is available alongside the original.\footnote{\url{removed for review}}

% system1:
% nivreeager
% LAS: 0.3341 [0.234 0.288 0.289 0.292 0.333 0.335 0.359 0.378 0.408 0.425]
% UAS: 0.5093 [0.413 0.464 0.465 0.466 0.474 0.499 0.531 0.545 0.604 0.632]

% system2:
% nivreeager
% LAS: 0.234+0.288+0.289+0.292+0.333+0.335+0.359+0.378+0.408+0.425
% UAS: 0.413+0.464+0.465+0.466+0.474+0.499+0.531+0.545+0.604+0.632

% system3:
% nivreeager
% LAS: 0.5529 [0.434 0.446 0.501 0.511 0.515 0.542 0.558 0.572 0.7 0.75]
% UAS: 0.7376 [0.658 0.669 0.675 0.684 0.694 0.723 0.751 0.776 0.825 0.921]

% system4:
% covnonproj
% LAS: 0.6092 [0.519 0.535 0.544 0.569 0.569 0.62 0.621 0.649 0.683 0.783]
% UAS: 0.7575 [0.674 0.686 0.69 0.714 0.727 0.746 0.795 0.803 0.812 0.928]

%             [0.434+0.446+0.501+0.511+0.515+0.542+0.558+0.572+0.7+0.75]
%             [0.658+0.669+0.675+0.684+0.694+0.723+0.751+0.776+0.825+0.921]

\begin{table}
\centering
  \begin{tabular}{|l|l|r|r|}
    \hline
    \textbf{Features}       & \textbf{Algorithm} &\textbf{LAS} & \textbf{UAS} \\
    \hline
     surface                & nivreeager  & 33.4 [23.4, 42.5] & 50.9 [41.3, 63.2] \\
     surface+lemma          & nivreeager  & 33.4 [23.4, 42.5] & 50.9 [41.3, 63.2] \\
     surface+lemma+POS      & nivreeager  & 55.2 [43.4, 75.0] & 73.7 [65.8, 92.1] \\
     surface+lemma+POS+MSD  & nivreeager  & 55.2 [43.4, 75.0] & 73.7 [65.8, 92.1] \\
    \hline
  \end{tabular}
  \caption{Preliminary parsing results from MaltParser using different models. The numbers in 
    brackets denote the upper and lower bounds found during cross validation. Adding 
    structural features to the model substantially improves the performance of the parser, although
    we find no improvement in using full morphosyntactic description (MSD) over using
    simply the first part-of-speech (POS) tag.}
  \label{table:eval}
\end{table}

To perform 10-fold cross validation we randomised the order of sentences in the corpus
and split it into 10 equally-sized parts. In each iteration we held out one part for testing and used
the rest for training. We calculated the labelled-attachment score (LAS) and 
unlabelled-attachment score (UAS) for each of the models.

The results we obtain are similar to those obtained with similar 
sized treebanks, for example the Irish treebank of \cite{Lynn12}, who report an LAS of
63.3 and a UAS of 73.3 with the best model.
