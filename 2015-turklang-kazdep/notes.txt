==Introduction==

This article describes the work towards the development of a dependency treebank for Kazakh, a 
Turkic language spoken in Central Asia. 
Despite its status as a \emph{core} Turkic
language, little computational-linguistic research has been published on syntactic
parsing for Kazakh. 
A valuable resource in the study of syntactic parsing is 
a treebank---a corpus of parsed text containing gold-standard syntactic annotation. 

Freely available treebanks exist for many languages, such as large languages like Finnish (x,y)
and Polish (xxx) and smaller languages like Irish (zz). To our knowledge only one treebank
exists for another language, Turkish (yyy), which is unfortunately not freely available.

In building our treebank we take advantage of existing work done on tokenisation,
morphological analysis and part-of-speech tagging for Kazakh. We also take a pragmatic
and iterative view of development of the treebank, in line with recent work 
on cross-linguistic parsing with universal dependencies.

The remainder of the paper is organised as follows. Section~\ref{sec:back} gives some 
background linguistic information on Kazakh, and outlines some special challenges in 
parsing Kazakh. In Section~\ref{sec:method} we describe the corpus itself and methodology
used in annotating it. Section~\ref{sec:annotation} gives a sketch of some decisions
we have made with respect to annotation guidelines, referring back to the discussion in 
Section~\ref{sec:back}. For reasons of space, these guidelines are not complete, but 
present a subset of guidelines which are of particular interest. A small experiment
in statistical dependency parsing using the corpus is presented in Section~\ref{sec:eval},
and in Sections~\ref{sec:future} and \ref{sec:conclusions} we give perspectives
for future work and some concluding remarks.

==Treebanks==

A treebank is a parsed corpus of sentences annotated syntactically following a particular
syntactic theory. Two broad groups can be distinguished, phrase-structure treebanks
which annotate constituency strucure, and dependency treebanks which annotate dependency
structure. Some treebanks combine both.

Treebanks can be used directly for linguistic and computational linguistic research, by 
performing search queries. For example, to extract a valency lexicon for verbs, or to 
study the frequency of various syntactic phenomena such as word order or nominal case usage
and syntactic function.

They can also be used to train statistical parsers which can
be used to annotate previously unseen texts. These parsers can be used in end-user applications
such as machine translation and computer-aided language learning.

According to \cite{nivre08}, a parser trained on a treebank of only 1,500 sentences 
can provide reasonable parsing accuracy.


==Corpora==


"<Елде>"
        "ел" n loc 
"<экономикалық>"
        "экономикалық" adj 
"<және>"
        "және" cnjcoo 
"<мәдени>"
        "мәдени" adj 
"<өрлеу>"
        "өрлеу" n nom 
"<байқалып>"
        "байқа" v tv pass gna_perf 
"<,>"
        "," cm 
"<қалалар>"
        "қала" n pl nom 
"<өсе>"
        "өс" v iv prc_impf 
"<бастады>"
        "баста" vaux ifi p3 pl 
"<.>"
        "." sent 


"<Елде>"
        "ел" n loc 
"<ағылшын>"
        "ағылшын" n nom 
"<үстемдігіне>"
        "үстемдік" n px3sp dat 
"<қарсы>"
        "қарсы" post 
"<жаңа>"
        "жаңа" adj 
"<толқулар>"
        "толқу" n pl nom 
"<басталды>"
        "баста" v tv pass ifi p3 pl 
"<.>"
        "." sent 

"<Ол>"
        "ол" det dem 
"<толқулар>"
        "толқу" n pl nom 
"<күшпен>"
        "күш" n ins 
"<басылып>"
        "бас" v tv pass prc_perf 
"<отырды>"
        "отыр" vaux ifi p3 pl 
"<.>"
        "." sent 


===Tokens and words===

Tokenisation of the corpus is performed by our morphological analyser. This analyser
performs tokenisation on the basis of a left-to-right longest match algorithm described
in \textcite{garrido02}. Simple tokens such as \emph{толқулар} `riots' are maintained 
as a single token, and their lemma and morphological analysis is returned. Multiword
units such as \emph{ауа райы} `weather' and \emph{ата-ананың} `of parents' are combined
into a single token. Abbreviations and numerals which bear case, such as АҚШ-пен `with the USA'
and \emph{90%-ына} `to the 90\%' are analysed as a single token, as are light-verbs such as
\emph{пайда бол} `to appear' and tense forms written with space like \emph{оқыған жоқ}, 
the third-person negative past of \emph{оқы} `to learn'. 

In some cases a single token is split into two tokens, as with the aorist copula suffixes, 
\emph{үйдемін} `I am in the house' is tokenised as үй.{\sc loc} + е.{\sc cop.aor.sg1}. Furthermore
two input tokens may result in three output tokens, \emph{бар ма?} `is there?' would be 
tokenised as бар.{\sc adj} + е.{\sc cop.aor.sg1} + ма.{\sc qst}.

%Simple tokens:
%	толқулар = толқу.{\sc pl.nom}
%
%Multiword units:
%	ауа райы = ауа̣ райы.{\sc nom}
%	ата-анасы = ата-ана.{\sc px3sg.nom}
%	АҚШ-пен = АҚШ.{\sc ins}
%	
%Abbreviations:
%	90%-ына = 90.{\sc percent.px3sp.dat}
%
%Copula:
%	үйдемін = үй.{\sc loc}+е.{\sc cop.aor.sg1}
%
%Clitics:
%	бар ма? = бар.{\sc adj}+е.{\sc cop.aor.sg3}+ма.{\sc qst}
%	
%Light verbs:
%	пайда болған = пайда бол.{\sc past}
%
%Part of tense:
%	оқыған жоқ = оқы.{\sc neg.past}


==Evaluation==

In order to test the utility of the treebank in a real-world setting, we trained
and evaluated a number of models using the popular MaltParser tool \citep{nivre07}.
MaltParser is a toolkit for data-driven dependency parsing, it can learn a parsing
model from treebank data and apply this model to parse unseen sentences. The parser
has a large number of options and parameters that need to be optimised. 
To select the best parser configuration we relied on 
MaltOptimiser \citep{ballesteros15}. The optimiser was run separately for each of 
the model configurations.

As the treebank takes advantage of the new tokenisation standards in the CoNLL-U format,
and MaltParser only supports CoNLL-X, certain transformations were needed to perform 
the experiments. The corpus was flattened with conjoined tokens receiving a dummy 
surface form. The converted corpus is available alongside the original.\footnote{\url{removed for review}}

% system1:
% nivreeager
% LAS: 0.3341 [0.234 0.288 0.289 0.292 0.333 0.335 0.359 0.378 0.408 0.425]
% UAS: 0.5093 [0.413 0.464 0.465 0.466 0.474 0.499 0.531 0.545 0.604 0.632]

% system2:
% nivreeager
% LAS: 0.234+0.288+0.289+0.292+0.333+0.335+0.359+0.378+0.408+0.425
% UAS: 0.413+0.464+0.465+0.466+0.474+0.499+0.531+0.545+0.604+0.632

% system3:
% nivreeager
% LAS: 0.5529 [0.434 0.446 0.501 0.511 0.515 0.542 0.558 0.572 0.7 0.75]
% UAS: 0.7376 [0.658 0.669 0.675 0.684 0.694 0.723 0.751 0.776 0.825 0.921]

% system4:
% covnonproj
% LAS: 0.6092 [0.519 0.535 0.544 0.569 0.569 0.62 0.621 0.649 0.683 0.783]
% UAS: 0.7575 [0.674 0.686 0.69 0.714 0.727 0.746 0.795 0.803 0.812 0.928]

%             [0.434+0.446+0.501+0.511+0.515+0.542+0.558+0.572+0.7+0.75]
%             [0.658+0.669+0.675+0.684+0.694+0.723+0.751+0.776+0.825+0.921]

\begin{table}
\centering
  \begin{tabular}{|l|l|r|r|}
    \hline
    \textbf{Features}       & \textbf{Algorithm} &\textbf{LAS} & \textbf{UAS} \\
    \hline
     surface                & nivreeager  & 33.4 [23.4, 42.5] & 50.9 [41.3, 63.2] \\
     surface+lemma          & nivreeager  & 33.4 [23.4, 42.5] & 50.9 [41.3, 63.2] \\
     surface+lemma+POS      & nivreeager  & 55.2 [43.4, 75.0] & 73.7 [65.8, 92.1] \\
     surface+lemma+POS+MSD  & nivreeager  & 55.2 [43.4, 75.0] & 73.7 [65.8, 92.1] \\
    \hline
  \end{tabular}
  \caption{Preliminary parsing results from MaltParser using different models. The numbers in 
    brackets denote the upper and lower bounds found during cross validation. Adding 
    structural features to the model substantially improves the performance of the parser, although
    we find no improvement in using full morphosyntactic description (MSD) over using
    simply the first part-of-speech (POS) tag.}
  \label{table:eval}
\end{table}

To perform 10-fold cross validation we randomised the order of sentences in the corpus
and split it into 10 equally-sized parts. In each iteration we held out one part for testing and used
the rest for training. We calculated the labelled-attachment score (LAS) and 
unlabelled-attachment score (UAS) for each of the models.

The results we obtain are similar to those obtained with similar 
sized treebanks, for example the Irish treebank of \cite{Lynn12}, who report an LAS of
63.3 and a UAS of 73.3 with the best model.
