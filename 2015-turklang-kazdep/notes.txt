==Abstract==

This article describes the first steps towards a free/open-source dependency treebank for Kazakh based on 
universal dependency (UD) annotation standards. The treebank contains 30
2 sentences and is based on texts from a range of open-source and public domain sources. This ensures 
its free availability and extensibility. Texts in the treebank are first morphologically analysed 
and disambiguated and then annotated manually for dependency structure. In the article we present 
some issues in dependency syntax for Kazakh and how these are analysed in the universal-dependency 
framework. Preliminary results for statistical dependency parsing of Kazakh are reported, along with
some directions for future research.


==Introduction==

This article describes the work towards the development of a dependency treebank for Kazakh, a 
Turkic language spoken in Central Asia. 
Despite its status as a \emph{core} Turkic
language, little computational-linguistic research has been published on syntactic
parsing for Kazakh. 
A valuable resource in the study of syntactic parsing is 
a treebank---a corpus of parsed text containing gold-standard syntactic annotation. 

Freely available treebanks exist for many languages, such as large languages like Finnish (x,y)
and Polish (xxx) and smaller languages like Irish (zz). To our knowledge only one treebank
exists for another language, Turkish (yyy), which is unfortunately not freely available.

In building our treebank we take advantage of existing work done on tokenisation,
morphological analysis and part-of-speech tagging for Kazakh. We also take a pragmatic
and iterative view of development of the treebank, in line with recent work 
on cross-linguistic parsing with universal dependencies.

The remainder of the paper is organised as follows. Section~\ref{sec:back} gives some 
background linguistic information on Kazakh, and outlines some special challenges in 
parsing Kazakh. In Section~\ref{sec:method} we describe the corpus itself and methodology
used in annotating it. Section~\ref{sec:annotation} gives a sketch of some decisions
we have made with respect to annotation guidelines, referring back to the discussion in 
Section~\ref{sec:back}. For reasons of space, these guidelines are not complete, but 
present a subset of guidelines which are of particular interest. A small experiment
in statistical dependency parsing using the corpus is presented in Section~\ref{sec:eval},
and in Sections~\ref{sec:future} and \ref{sec:conclusions} we give perspectives
for future work and some concluding remarks.

==Treebanks==

A treebank is a parsed corpus of sentences annotated syntactically following a particular
syntactic theory. Two broad groups can be distinguished, phrase-structure treebanks
which annotate constituency strucure, and dependency treebanks which annotate dependency
structure. Some treebanks combine both.

Treebanks can be used directly for linguistic and computational linguistic research, by 
performing search queries. For example, to extract a valency lexicon for verbs, or to 
study the frequency of various syntactic phenomena such as word order or nominal case usage
and syntactic function.

They can also be used to train statistical parsers which can
be used to annotate previously unseen texts. These parsers can be used in end-user applications
such as machine translation and computer-aided language learning.

According to \cite{nivre08}, a parser trained on a treebank of only 1,500 sentences 
can provide reasonable parsing accuracy.


==Corpora==


"<Елде>"
        "ел" n loc 
"<экономикалық>"
        "экономикалық" adj 
"<және>"
        "және" cnjcoo 
"<мәдени>"
        "мәдени" adj 
"<өрлеу>"
        "өрлеу" n nom 
"<байқалып>"
        "байқа" v tv pass gna_perf 
"<,>"
        "," cm 
"<қалалар>"
        "қала" n pl nom 
"<өсе>"
        "өс" v iv prc_impf 
"<бастады>"
        "баста" vaux ifi p3 pl 
"<.>"
        "." sent 


"<Елде>"
        "ел" n loc 
"<ағылшын>"
        "ағылшын" n nom 
"<үстемдігіне>"
        "үстемдік" n px3sp dat 
"<қарсы>"
        "қарсы" post 
"<жаңа>"
        "жаңа" adj 
"<толқулар>"
        "толқу" n pl nom 
"<басталды>"
        "баста" v tv pass ifi p3 pl 
"<.>"
        "." sent 

"<Ол>"
        "ол" det dem 
"<толқулар>"
        "толқу" n pl nom 
"<күшпен>"
        "күш" n ins 
"<басылып>"
        "бас" v tv pass prc_perf 
"<отырды>"
        "отыр" vaux ifi p3 pl 
"<.>"
        "." sent 


===Tokens and words===

Tokenisation of the corpus is performed by our morphological analyser. This analyser
performs tokenisation on the basis of a left-to-right longest match algorithm described
in \textcite{garrido02}. Simple tokens such as \emph{толқулар} `riots' are maintained 
as a single token, and their lemma and morphological analysis is returned. Multiword
units such as \emph{ауа райы} `weather' and \emph{ата-ананың} `of parents' are combined
into a single token. Abbreviations and numerals which bear case, such as АҚШ-пен `with the USA'
and \emph{90%-ына} `to the 90\%' are analysed as a single token, as are light-verbs such as
\emph{пайда бол} `to appear' and tense forms written with space like \emph{оқыған жоқ}, 
the third-person negative past of \emph{оқы} `to learn'. 

In some cases a single token is split into two tokens, as with the aorist copula suffixes, 
\emph{үйдемін} `I am in the house' is tokenised as үй.{\sc loc} + е.{\sc cop.aor.sg1}. Furthermore
two input tokens may result in three output tokens, \emph{бар ма?} `is there?' would be 
tokenised as бар.{\sc adj} + е.{\sc cop.aor.sg1} + ма.{\sc qst}.

%Simple tokens:
%	толқулар = толқу.{\sc pl.nom}
%
%Multiword units:
%	ауа райы = ауа̣ райы.{\sc nom}
%	ата-анасы = ата-ана.{\sc px3sg.nom}
%	АҚШ-пен = АҚШ.{\sc ins}
%	
%Abbreviations:
%	90%-ына = 90.{\sc percent.px3sp.dat}
%
%Copula:
%	үйдемін = үй.{\sc loc}+е.{\sc cop.aor.sg1}
%
%Clitics:
%	бар ма? = бар.{\sc adj}+е.{\sc cop.aor.sg3}+ма.{\sc qst}
%	
%Light verbs:
%	пайда болған = пайда бол.{\sc past}
%
%Part of tense:
%	оқыған жоқ = оқы.{\sc neg.past}


===General annotation procedure===

Annotation of the treebank followed an iterative approach. The first stage was to 
select a text and preprocess it using the morphological analyser and constraint grammar.
The output of this process was then manually disambiguated by choosing the most appropriate
analysis in context, or adding a new analysis if one was not returned by the morphological
analyser. This latter step was mostly in the case of unknown proper nouns.\footnote{New lexemes
found during the development of the corpus will contribute to the development of the 
morphological analyser.}

After the text was disambiguated, it was annotated by a single annotator for dependency
structure relying on the annotation guidelines for universal dependencies.\footnote{\url{http://universaldependencies.github.io/docs/u/overview/syntax.html}}

Where it was not clear how to annotate a particular structure, it was left pending, that
is marked with the {\sc dep} relation. After a text was annotated, graphical representations
of the trees were produced and proofread by a second annotator. The final analysis for a 
sentence was decided on during discussions between the two annotators and in some cases
through the universal-dependency issue tracker.\footnote{\url{https://github.com/UniversalDependencies/docs/issues/}}

During the course of annotation, language-specific annotation guidelines for Kazakh are
being produced and published online.\footnote{\url{http://wiki.apertium.org/wiki/Dependency_parsing_for_Turkic}}

==Copula==

The copula (both \emph{е} and \emph{бол}) is a challenging problem for dependency 
analysis of Kazakh. The universal dependency guidelines state that the copula should
be the dependent of the lexical predicate. However, in many cases the copula in Kazakh
is found in embedded clauses ...

We have uniformly annotated the copula as a leaf node with the predicate, or adverbial
as the head of the structure. For certain structures this is convenient, such as the 
bare copula in phrases like \ref{ex:cop1} or \ref{ex:cop2}, but for phrases where
the copula is part of an embedded clause this is not necessarily the most 
effective choice. In \ref{ex:cop3}, the copula holds all the morphological information, 
agreement with the subject and accusative marking for the embedded clause. 

\begin{figure}[htbp]
        \centering

        \begin{subfigure}[b]{0.25\textwidth}
                \centering
                \begin{dependency}[theme = simple, font = \small]
                   \begin{deptext}[column sep=0.2cm]
                                Айгүл \& студент \& · \\
                                \gmk{np} \& \gmk{n} \& \gmk{aor} \\
                                \gloss{Aygül} \& \gloss{student} \& \gloss{is} \\
                        \end{deptext} 
                        \deproot[edge unit distance=1.3ex]{2}{\udlabel{root}}
                        \depedge{2}{1}{\udlabel{subj}}
                        \depedge{2}{3}{\udlabel{cop}}
                \end{dependency}
                \caption{Non-surfaced copula.}\label{fig:cop1}
        \end{subfigure}
        \quad
        \begin{subfigure}[b]{0.25\textwidth}
                \centering
                \begin{dependency}[theme = simple, font = \small]
                   \begin{deptext}[column sep=0.2cm]
                                Айгүл \& студент \& болған \\
                                \gmk{np} \& \gmk{n} \& \gmk{past} \\
                                \gloss{Aygül} \& \gloss{student} \& \gloss{was}\\
                        \end{deptext} 
                        \deproot[edge unit distance=1.3ex]{2}{\udlabel{root}}
                        \depedge{2}{1}{\udlabel{subj}}
                        \depedge{2}{3}{\udlabel{cop}}
                \end{dependency}
                \caption{Copula in past tense.}\label{fig:cop2}
        \end{subfigure}
        \quad
        \begin{subfigure}[b]{0.40\textwidth}
                \centering
                \begin{dependency}[theme = simple, font = \small]
                   \begin{deptext}[column sep=0.2cm]
                                Айгүл \& оның \& қайда \& екенін \& білмейді. \\
                                \gmk{np} \& \gmk{gen} \& \gmk{adv} \& \gmk{cop} \& \gmk{neg.aor} \\
                                \gloss{Aygül} \& \gloss{he} \& \gloss{where} \& \gloss{being} \& \gloss{knows not} \\
                        \end{deptext}
                        \deproot[edge unit distance=1.3ex]{5}{\udlabel{root}}
                        \depedge{3}{2}{\udlabel{subj}}
                        \depedge{5}{3}{\udlabel{ccomp}}
                        \depedge{3}{4}{\udlabel{cop}}
                \end{dependency}
                \caption{Copula in an embedded clause.}\label{fig:cop3}
        \end{subfigure}
        \caption{Dependency trees of copula constructions.}
\end{figure}

                                                                                                                                                                362,20        65%


==Coordination==

One difference in our annotation scheme compared to the standard universal dependency 
analysis is with coordination. While the universal dependency scheme takes the first
conjunct as the head, we take the last. This decision was made based on the fact that
Kazakh is a head-final language and morphological marking is only obligatory on the 
last conjunct in a series. Furthermore, experiments in representing coordination
in other head-final languages have found that the final-conjunct head analysis 
results in better parser accuracy \parencite{bengoetxea09}. 


\begin{figure}[htbp]
    \centering

        \begin{dependency}[theme = simple, font = \small]
           \begin{deptext}[column sep=0.08cm]
%               1         2         3          4              5          6          7        8 
                Олар \& Финляндия, \& Швеция \& және \& Эстонияидан \& кейін \& Ресейге \& барды. \\
                \gmk{prn} \& \gmk{nom} \& \gmk{nom} \& \gmk{cc} \& \gmk{abl} \& \gmk{post} \& \gmk{dat} \& \gmk{past} \\ 
                \gloss{They} \& \gloss{Finland}, \& \gloss{Sweden} \& \gloss{and} \& \gloss{Estonia} \& \gloss{after} \& \gloss{Russia} \& \gloss{visited.} \\
                \end{deptext}
                \depedge{5}{3}{\udlabel{conj}}
                \depedge{5}{4}{\udlabel{cc}}
                \depedge{5}{2}{\udlabel{conj}}
                \depedge{5}{6}{\udlabel{case}}
                \depedge{8}{5}{\udlabel{nmod}}
                \depedge{8}{7}{\udlabel{nmod}}
        \end{dependency}
        \caption{Coordination: All conjucts are attached to the final conjunct, which is the head of the coordinated phrase.}\label{fig:coord}

\end{figure}


==Evaluation==

In order to test the utility of the treebank in a real-world setting, we trained
and evaluated a number of models using the popular MaltParser tool \citep{nivre07}.
MaltParser is a toolkit for data-driven dependency parsing, it can learn a parsing
model from treebank data and apply this model to parse unseen sentences. The parser
has a large number of options and parameters that need to be optimised. 
To select the best parser configuration we relied on 
MaltOptimiser \citep{ballesteros15}. The optimiser was run separately for each of 
the model configurations.

As the treebank takes advantage of the new tokenisation standards in the CoNLL-U format,
and MaltParser only supports CoNLL-X, certain transformations were needed to perform 
the experiments. The corpus was flattened with conjoined tokens receiving a dummy 
surface form. The converted corpus is available alongside the original.\footnote{\url{removed for review}}

% system1:
% nivreeager
% LAS: 0.3341 [0.234 0.288 0.289 0.292 0.333 0.335 0.359 0.378 0.408 0.425]
% UAS: 0.5093 [0.413 0.464 0.465 0.466 0.474 0.499 0.531 0.545 0.604 0.632]

% system2:
% nivreeager
% LAS: 0.234+0.288+0.289+0.292+0.333+0.335+0.359+0.378+0.408+0.425
% UAS: 0.413+0.464+0.465+0.466+0.474+0.499+0.531+0.545+0.604+0.632

% system3:
% nivreeager
% LAS: 0.5529 [0.434 0.446 0.501 0.511 0.515 0.542 0.558 0.572 0.7 0.75]
% UAS: 0.7376 [0.658 0.669 0.675 0.684 0.694 0.723 0.751 0.776 0.825 0.921]

% system4:
% covnonproj
% LAS: 0.6092 [0.519 0.535 0.544 0.569 0.569 0.62 0.621 0.649 0.683 0.783]
% UAS: 0.7575 [0.674 0.686 0.69 0.714 0.727 0.746 0.795 0.803 0.812 0.928]

%             [0.434+0.446+0.501+0.511+0.515+0.542+0.558+0.572+0.7+0.75]
%             [0.658+0.669+0.675+0.684+0.694+0.723+0.751+0.776+0.825+0.921]

\begin{table}
\centering
  \begin{tabular}{|l|l|r|r|}
    \hline
    \textbf{Features}       & \textbf{Algorithm} &\textbf{LAS} & \textbf{UAS} \\
    \hline
     surface                & nivreeager  & 33.4 [23.4, 42.5] & 50.9 [41.3, 63.2] \\
     surface+lemma          & nivreeager  & 33.4 [23.4, 42.5] & 50.9 [41.3, 63.2] \\
     surface+lemma+POS      & nivreeager  & 55.2 [43.4, 75.0] & 73.7 [65.8, 92.1] \\
     surface+lemma+POS+MSD  & nivreeager  & 55.2 [43.4, 75.0] & 73.7 [65.8, 92.1] \\
    \hline
  \end{tabular}
  \caption{Preliminary parsing results from MaltParser using different models. The numbers in 
    brackets denote the upper and lower bounds found during cross validation. Adding 
    structural features to the model substantially improves the performance of the parser, although
    we find no improvement in using full morphosyntactic description (MSD) over using
    simply the first part-of-speech (POS) tag.}
  \label{table:eval}
\end{table}

To perform 10-fold cross validation we randomised the order of sentences in the corpus
and split it into 10 equally-sized parts. In each iteration we held out one part for testing and used
the rest for training. We calculated the labelled-attachment score (LAS) and 
unlabelled-attachment score (UAS) for each of the models.

The results we obtain are similar to those obtained with similar 
sized treebanks, for example the Irish treebank of \cite{Lynn12}, who report an LAS of
63.3 and a UAS of 73.3 with the best model.

==Future work==

Future work will focus on improving the annotation guidelines and the consistency of 
annotation in the corpus. We will also study the possibility of deepening the annotation
with Turkic-specific relations. When we have stable annotation guidelines we intend to 
extend the corpus with more texts. 
We would also like to work on cross-lingual dependency parsing,
that is, applying a model learnt on the Kazakh treebank to other Turkic languages 
such as Tatar, Kumyk and Tuvan. We have morphological analysers for these languages which have
compatible tagsets for morphological features and as such it should be possible to learn a 
delexicalised model based on these features. As Turkic syntax is broadly homogenous, this 
presents a promising avenue for future work.

==Concluding remarks==

We have presented the first steps towards a free/open-source dependency treebank for 
Kazakh with annotation based on the universal dependencies. The treebank is small, but 
provides a base for bootstrapping further. Performance of a state-of-the-art statistical
parser trained on the treebank is comparable to other treebanks of similar size.


