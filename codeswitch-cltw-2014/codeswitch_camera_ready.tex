%Try1: akshay minocha
%
% File coling2014.tex
%
% Contact: jwagner@computing.dcu.ie

\documentclass[11pt]{article}
\usepackage{coling2014}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{alltt}
\usepackage[small,bf]{caption}
\usepackage{multirow}

%\setlength\titlebox{5cm}

\title{Subsegmental language detection in Celtic language text}

\author{}
\author{Akshay Minocha \\
  IIIT Hyderabad  \\
  Hyderabad (India) \\
  {\small {\tt akshay.minocha@students.iiit.ac.in}} \\\And
  Francis M. Tyers \\
  Giellatekno / CLEAR \\
  UiT Norgga \'arktala\v{s} universitehta  \\
  9017 Romsa (Norway) \\
  {\small {\tt francis.tyers@uit.no}} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
  Bilingual communities contribute majorly to the code-switching phenomena, where speakers produce sentences containing words and expressions from a second language. With the increase in the data on the web, specially on informal platforms like that of the social media, it becomes increasingly important to detect such irregularities and handle them appropriately. In this paper we propose ways of dealing with code-switching and detecting sub-segments for texts in three Celtic languages: Breton, Irish and Welsh. 
\end{abstract}

\section{Introduction}
\label{intro}

Determining the language of a piece of text is one of the first steps that must be taken
before proceeding with further computational processing. This task has received a substantial amount of
attention in recent years \cite{cavnar1994n,lui2012langid}. However, previous research has on the whole assumed
that a given text will be in a single language. When dealing with text from formal domains,
this may be the case --- although there are exceptions --- such as quotations embedded in
the text in another language. But when dealing with informal text, particularly in languages
where the speech community is predominantly bi- or multi-lingual, this assumption may not hold.

There are several ways in which an informal text may contain parts in different languages, such as
code switching, quotations, named entities, interjections, translations, etc. Some of these are presented
in Table~\ref{table:examples}.

The work presented in this paper was motivated by the problems in normalising non-standard input
for the Celtic languages as a precursor to machine translation. When applying a normalisation 
strategy to a piece of text, it is necessary to first know the language of the piece of text you 
are applying it to.

The remainder of the paper is laid out as follows. In section~\ref{sec:method} we describe the problem
in more detail and look at relevant prior work before proposing a novel method of sub-sentential
language detection. Section~\ref{sec:eval} describes the evaluation methodology. Then in section~\ref{sec:results}
we present the results of our method and compare it against several other possible methods. Finally, section~\ref{sec:conclusions}
presents future work and conclusions.

\begin{table}[h]
\begin{center}
\begin{tabular}{ll}
 \textbf{Code switching}: & You're a [Meirice\'{a}nach, c\'{e}n f\'{a}th] are you [foghlaim Gaeilge?!] \\
\textbf{Quotations}: & The anthem starts with the words [`Mae hen wlad fy nhadau\ldots'] \\
 \textbf{Named entities}: & [Dr Jekyll] ha [Mr Hyde] embannet gant [\'{E}ditions Aber] \\
 \textbf{Interjections}: & Hey, that's great, [diolch yn fawr!] \\
 \textbf{Translations}: & Bloavezh mat d'an holl ! [Bonne ann\'{e} \`{a} tous !] \\
\end{tabular}
\caption{Some examples of text segments containing more than one language}
\label{table:examples}
\end{center}
\end{table}


\section{Related Work}
\label{sec:relwork}

Code-switching and segment detection problems have been the subject of previous research. A good deal of work
has been done on detecting code-switched segments in speech data \cite{chan2004detection,lyu2006language}.
It is seen that language modelling techniques have shown promise earlier, such as in \newcite{yu2013identification} 
the experiment on Mandarin-Taiwanese code-switched sentences show a high accuracy in terms of detecting code-switched sentences. \\

\newcite{chan2004detection} has made use of the bi-phone probabilities and calculated them to measure a confidence metric, 
to \cite{lyu2006language} which has made use of a classification method, named syllable-based duration classification, 
which uses the tonal syllable properties along with the speech signals to help predict the code switch points. \newcite{yeong2010language} 
uses syllable structure information to identify words in code-switched text in Malay-English, however they did not 
recognise segments in running text, only identifying individual words.

%Our idea of going to character level inspection has been inspired both by the language modelling techniques used by the community as well as the acoustic modelling research. 

\section{Methodology}
\label{sec:method}
We use the character n-gram approach along with some heuristics which are relevant to our problem domain of identifying
segments for subsequent processing. We would like 
to both predict the code switched points but looking at the surrounding structure also decide the inclusion of them 
into the current or the next segment.\footnote{The software used in this experiment is available online at: \url{removed for review}.}

\subsection{Alphabet n-gram approach}
\label{alphan}

We first built character language models using IRSTLM \cite{federico08a} for the five languages in question. For English
and French a model was trained using the EuroParl corpus \cite{koehn2005europarl}. 
For Breton, Welsh and Irish we used corpora of text crawled from the web. For each of the languages we sampled 1.5 million words. The accuracy of the results saturate after the size of the dataset is around 1 million, and also since our collected corpus for Irish was around 1.5 million words we chose the limit of the sample to be this which also ensures no bias in the sampling of the languages. \\
In order to build a character language model as opposed to the standard word-ngram based model we replaced spaces with the underscore 
symbol `\_', and then placed a space character between each character. Punctuations and non letters are also part of this language model as we didn't mean to preserve the identity of the language being used in the original form. For example, `sl\'{a}inte' would be broken down into a sequence 
of \{`\_ s', `s l', `l \'{a}', `\'{a} i', `i n', `n t', `t e', `e \_'\}. 

%Then the probability for the alphabet sequence is calculated 
%for each language to be used in the experiment. 
%Improved Kneser-Ney is used for smoothing, and this smoothing approach would be useful 
%for higher-grams. \cite{kneser1995improved} \\

\subsection{Sequence chunking}
\label{cschunking}

This section describes the heuristics taken into account while performing the chunking of the input data according to 
the sequences of segments in different languages.

A flag is set at the beginning of the input text, and this moves forward to the position in the text upto where confident 
chunking has been performed. For example, in case of a continuous prediction there would be no change and since the 
predicted tag of the new word corresponds to that already of the expanding chunk, this word is also included in the 
same chunk. In case of a doubt, the flag is set at the same position, and no final decision on labelling the word is 
performed, to have more confidence on the code-switch, the process moves on to the next token, if it corresponds to 
that of the previous chunk, then both these undecided words are labelled and included in the chunk, otherwise a change 
is noted and a new chunk is created with the changed label. In this process, we are trying to identify the sub-segments 
that we need, thus performing both tasks at once, the first being language prediction and second being the chunking decision. 

\subsection{Word-based prediction}
\label{wbased}

This is a simple heuristic which was designed on the basis of the the most common words in the wordlists of the languages 
which are in question. After checking each word against both of the word lists,\footnote{For the wordlists we used the \emph{aspell}
wordlists widely available on Unix systems.} it is associated to one language or another. In 
case of a conflict, for example, when the word exists in both wordlists, or in the case that it is unknown to both, the option 
of continuing with the previous span was taken and the previous selected tag was labelled, thus increasing the chunk. 

\subsection{Word-based prediction with character backoff}
\label{wbasedbackoff}

A better way to predict the spans of the sub-segments of the text is to include the two methods of word and character-based techniques 
as described above. In case of the word being present in only one of the two monolingual word lists the classification is simple, 
but in case of a conflict, a character bigram backoff was introduced to help us disambiguate the language label. This method works well because the earlier heuristic approach of just labelling the word with the label of the span which is expanding, would mean less code-switch detection and more shift towards the majority class. 


% issues:
%% proper nouns
%% other language interjections (f√°ilte), diolch, diolch yn fawr
%% spelling
%% abbreviations


%
% The following footnote without marker is needed for the camera-ready
% version of the paper.
% Comment out the instructions (first text) and uncomment the 8 lines
% under "final paper" for your variant of English.
%

\blfootnote{
    %
    % for review submission
    %
    \hspace{-0.65cm}  % space normally used by the marker
    Place licence statement here for the camera-ready version, see
    Section~\ref{licence} of the instructions for preparing a
    manuscript.
    %
    % % final paper: en-uk version (to license, a licence)
    %
    % \hspace{-0.65cm}  % space normally used by the marker
    % This work is licensed under a Creative Commons 
    % Attribution 4.0 International Licence.
    % Page numbers and proceedings footer are added by
    % the organisers.
    % Licence details:
    % \url{http://creativecommons.org/licenses/by/4.0/}
    % 
    % % final paper: en-us version (to licence, a license)
    %
    % \hspace{-0.65cm}  % space normally used by the marker
    % This work is licenced under a Creative Commons 
    % Attribution 4.0 International License.
    % Page numbers and proceedings footer are added by
    % the organizers.
    % License details:
    % \url{http://creativecommons.org/licenses/by/4.0/}
}

\section{Evaluation}
\label{sec:eval}

We hand-annotated a small evaluation set from a selection of posts to a popular microblogging site\footnote{\url{http://indigenoustweets.blogspot.in/2013/12/mapping-celtic-twittersphere.html}}. The posts `tweets' were filtered into three sets which had been identified as Irish, Welsh and Breton.  Certain tokens were escaped from the data, such as mentioned (which are preceded by an \texttt{@} symbol), subject tags `hashtags' which are preceded by a \texttt{\#} symbol), hyperlinks and the sequence \texttt{rt} which stands for `re-tweet'. An example of the content of our corpus after annotation is given in Figure~\ref{fig:tweets}. All of the tweets had at least one instance of code-switching.

For the Evaluation procedure, we follow the footsteps of the CoNLL-2000 shared task on language-independent 
named entity recognition: dividing text into syntactically related non-overlapping groups of words. This 
chunking mechanism \cite{tjong2003introduction} is very similar to ours, in terms of words which only belong to 
one category (here, language), and also evaluation based on the segment structure present in the data. The chunks 
here are such that they belong to only one language. 

\begin{figure}
\begin{small}
\begin{alltt}
[\textbf{en} You're a] [\textbf{ga} Meirice\'{a}nach, c\'{e}n f\'{a}th] [\textbf{en} are you] [\textbf{ga} foghlaim Gaeilge?!] 
@afaltomkins [\textbf{cy} gorfod cael bach o tan] [\textbf{en} though init] 
[\textbf{en} omg] [\textbf{cy} mar cwn bach yn] [\textbf{en} black and tan] [\textbf{cy} a popeth,] [\textbf{en} even cuter!!] 
\end{alltt}
\end{small}
\caption{Example of text from a microblogging site chunked}
\label{fig:tweets}
\end{figure}

For our current task, each of the texts have been limited to two languages i.e. the primary language (the Celtic language) and the 
secondary language (the `majority' language). Hence the type of chunking tags are limited to these. The evaluation statistics shown 
in Tables~\ref{table:precisionrecall}~and~\ref{table:accuracy} mention two values for each of the experiment conducted on the three bilingual 
language datasets. The first, is the percentage of correctly detected phrases, which is the overall precision and the second is the 
number of phrases in the data that were found by the chunker, which is the overall recall. \\

Apart from the techniques discussed in section~\ref{sec:method}, some baselines are also used to give a comparative view of how well all the mechanism perform.

\subsection{Baseline}
\label{baseline}

This is the most na\"{i}ve method of classification, we used the language identification tool \texttt{langid.py} \cite{lui2012langid} on the whole dataset and labelled all the individual lines according to this single majority classification. As no chunking is performed we can expect that the precision and recall will be very low. However it does provide a reasonable baseline for the per-word accuracy.  \\

\subsection{\texttt{langid} character bigram and trigram prediction}
\label{langidstuff}

After restricting the predicted languages to be amongst the two in the dataset, we used the character bigram and then trigram probabilities to predict the detected language for each token, some rules like in section~\ref{sec:method} were followed which included that the span of a segment or a code-switched phrase is more than a word, the social media non-language entities such as the hashtags, usernames and urls do not make a difference. 

\section{Results}
\label{sec:results}
As described in the ~\ref{sec:method} the data collected from Twitter for the three language pairs, was processed using the techniques mentioned. The statistics of the same are given in Table~\ref{table:datastats}. // 

\begin{table}
\begin{center}
\begin{tabular}{|l|r|r|r|r}
\hline
\multirow{2}{*}{\textbf{Pair}} & \multirow{2}{*}{\textbf{Language}}  & \multicolumn{2}{c|}{\textbf{Statistics} (\%)} \\\cline{3-4}
                &  &  Tokens & Segments \\
\hline
\multirow{2}{*}{Irish---English} & Irish & 332 & 40 \\
                                 & English & 379 & 42 \\
\hline
\multirow{2}{*}{Welsh---English} & Welsh & 419 & 64 \\
                                 & English & 378 & 66  \\
\hline
\multirow{2}{*}{Breton---French} & Breton & 388 & 54 \\
                                 & French & 379 & 53  \\
\hline
\end{tabular}
\end{center}
\caption{Document statistics of the annotated data used. }
\label{table:datastats}
\end{table}

\begin{table}
\begin{center}
\begin{tabular}{|lc|r|r|r|r|r|r|}
\hline
\multirow{2}{*}{\textbf{System}}            & & \multicolumn{2}{c}{\textbf{Irish---English}} & \multicolumn{2}{|c|}{\textbf{Welsh---English}} & \multicolumn{2}{c|}{\textbf{Breton---French}}  \\\cline{3-8}
                                          &      &  Irish &  English & Welsh  & English & Breton & French \\
\hline 
\multirow{2}{*}{\texttt{baseline}}        &  $p$ &  2.50   & 0.0      & 0.0   & 0.0 & 0.0 & 0.0 \\
                                          & $r$  & 2.56    & 0.0      & 0.0   & 0.0 & 0.0 & 0.0 \\
\hline
\multirow{2}{*}{\texttt{langid2}}         &  $p$ &  0.00   & 7.14     & 0.0   & 18.18    & 0.0 & 28.30 \\
                                          & $r$  & 0.00    & 5.00     & 0.0   & 14.12 & 0.0 & 18.99 \\
\hline
\multirow{2}{*}{\texttt{langid3}}         &  $p$ &  5.00   & 14.29    & 0.0   & 21.21 & 1.85 & 20.75 \\
                                          & $r$  & 5.41    & 8.45     & 0.0   & 14.58 & 1.92 & 12.36 \\
\hline
\multirow{2}{*}{\texttt{wordlist}}        &  $p$ &  32.50 & 28.57     & 26.69 & {\bf 40.91} & 57.41 & 33.96 \\
                                          & $r$  & 23.64  & 26.09     & {\bf 26.03} & {\bf 33.75} & 47.69 & 33.33 \\
\hline
\multirow{2}{*}{\texttt{bigram}}          &  $p$ &  32.50   & 35.71   & 23.44 & 19.70  & 57.41 & 52.83 \\
                                          & $r$  & 22.41    & 26.79   & 15.31 & 16.67 & 41.33 & 37.84 \\
\hline
\multirow{2}{*}{\texttt{wordlist+bigram}} &  $p$ &  {\bf 52.50}   & {\bf 50.00}   & {\bf 32.81} & 31.82 & {\bf 70.37} & {\bf 67.92} \\
                                          & $r$  & {\bf 38.18}    & {\bf 43.75}   & 24.14 & 25.61 & {\bf 57.58} & {\bf 57.14} \\
\hline
\end{tabular}
\end{center}
\caption{Precision, $p$ and recall, $r$ for the systems by language.}
\label{table:precisionrecall}

\end{table}


\begin{table}
\begin{center}
\begin{tabular}{|l|r|r|r|}
\hline
\multirow{2}{*}{\textbf{System}} &  \multicolumn{3}{c|}{\textbf{Accuracy} (\%)} \\\cline{2-4}
       &   Irish---English & Welsh---English & Breton---French \\ 
\hline
\texttt{baseline} & 42.76 & 42.16 & 44.07 \\
\hline
\texttt{langid2} & 50.35 & 42.28 & 45.11  \\
\hline
\texttt{langid3} & 57.24 & 45.92 & 43.16 \\
\hline
\texttt{wordlist} & 79.75 & \textbf{74.28} & 83.96 \\
\hline
\texttt{bigram} & 81.29 & 65.62 & 76.79 \\
\hline
\texttt{wordlist+bigram} & \textbf{85.79} & 72.40 & \textbf{88.79} \\
\hline
\end{tabular}
\end{center}
\caption{Accuracy of the systems over the three language pairs. The accuracy measures how often a token
  was assigned to the right language, independent of span.}
\label{table:accuracy}
\end{table}

In terms of per-word accuracy, the baseline performs as expected, given that half of the words in the test set are from a given language. 
The \texttt{langid.py} based methods allow for segmenting the text into chunks, but favour the majority language.\footnote{This could be because of the default models being used.} While the precision and recall are low for the remaining models, we see that we are able to improve 
the performance by combining the wordlist based model with a character bigram model. And what is more, we are able to begin to not only 
identify particular words in a language, but also segments.

\section{Conclusions}
\label{sec:conclusions}

This paper has presented a very preliminary investigation into subsegment language identification in Celtic language texts. We have
proposed a model that chunks input text into segments, and performs language identification on these segments at the same time. Precision and
recall are low, leaving a lot of room for further work. Some of our plans are as follows. We would like to annotate more test data,
at least 100 tweets in each language. We would also like to attempt our method using higher order character n-gram models for backoff, and
n-gram word language models for detection. 

% future work

%% bigger and better test data, and distributable
%% better evaluation -- significance testing
%%  evaluation by application
%% try it with scots gaelic
%% 
%% mikel's idea
%% higher order character n-gram models

\section*{Acknowledgements}

%We thank Kevin Scannell for help with providing data from Twitter and for useful comments and suggestions.

% include your own bib file like this:
\bibliographystyle{acl}
\bibliography{codeswitch}


\end{document}
