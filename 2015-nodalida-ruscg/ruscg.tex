%
% File nodalida2015.tex
%
% Contact beata.megyesi@lingfil.uu.se
%
% Based on the instruction file for EACL 2014
% which in turn was based on the instruction files for previous 
% ACL and EACL conferences.


\documentclass[11pt]{article}
\usepackage[T2A,T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian,english]{babel}

\usepackage{times}
\usepackage{latexsym}
\usepackage{fixltx2e} %allows subscripts
%\usepackage{mathptmx}
%\usepackage{txfonts}
\usepackage{url}
\usepackage[small,bf]{caption}
\special{papersize=210mm,297mm} % to avoid having to use "-t a4" with dvips 
%\setlength\titlebox{6.5cm}  % You can expand the title box if you really have to

\usepackage{nodalida2015}

\usepackage{linguex}
\usepackage{needspace}

\newcommand{\rus}[1]{\foreignlanguage{russian}{#1}}

\newcommand{\ft}[1]{\marginpar{\scriptsize F: #1}} % Fran's comments
\newcommand{\rr}[1]{\marginpar{\scriptsize R: #1}} % Rob's comments

\title{A preliminary constraint grammar for Russian}

\author{Francis M. Tyers \\
  HSL-fakultehta, \\
  UiT Norgga árktalaš universitehta, \\
  N-9018 Romsa \\
  {\tt francis.tyers@uit.no} \\\And
  Robert Reynolds \\
  HSL-fakultehta, \\
  UiT Norgga árktalaš universitehta, \\
  N-9018 Romsa \\
  {\tt robert.reynolds@uit.no} \\}

% \author{Author1 \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   {\tt email@domain.com} \\\And
%   Author2 \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   {\tt email@domain.com} \\}
% 
\date{2015}

\begin{document}
\maketitle
\begin{abstract}
 This paper presents preliminary work on a constraint
 grammar based disambiguator for Russian. Russian is
 a Slavic language with a high degree of both in-category
 and out-category homonymy in the inflectional system.
 The pipeline consists of a finite-state morphological
 analyser and constraint grammar. The constraint 
 grammar is tuned to be high recall at the expense of 
 low precision.
\end{abstract}

\section{Introduction}

Our purposes: Processing stressed wordforms and open-source machine translation

\cite{Karlsson-90}

% objectives:
%% make a free/open-source morphology for russian based on Z's dictionary that includes stress

\section{Review of literature}

State-of-the-art morphological analysis in Russian is primarily based on
finite-state technology
\cite{Nozhov-03,Segalovich-03}.\footnote{Machine-learning approaches have also been successfully applied to Russian, most notably by 
\newcite{sharoff08lrec-mocky}.} Almost without exception, all large-scale 
morphological transducers of Russian are based on the
forward-looking \emph{Grammatical Dictionary of Russian} \cite{Zaliznjak-77}.
This dictionary gives fine-grained morphological specifications for more than
100~000 words, including inflectional endings, morphophonemic alternations, 
stress patterns, exceptions, and idiosyncratic collocations.
We base our work on the recently developed [anonymous] morphological transducer, which is also based on Zaliznjak's dictionary (Author, 2015).\footnote{The [anonymous] transducer is implemented using a two-level 
morphology \cite{Koskenniemi-84}, and can be compiled using either {\tt xfst}
\cite{Beesley.Karttunen-03} or {\tt hfst} \cite{hfst-11}} This finite-state transducer (FST) generates all possible 
morphosyntactic readings of each wordform, regardless of its frequency or probability. Because Russian is a relatively highly inflected language, broad coverage is important, but widespread homonymy leads to the generation of many spurious readings, as discussed in Section~\ref{ambiguity} below. Because of this, one of the foundational steps in Russian natural language processing is morphosyntactic disambiguation, or \emph{snjatie omonimii}.

% FRAN
% different CGs 
% faroese
% estonian

 -- and our Constraint 
Grammar\footnote{Implemented using vislcg3 constraint grammar parser
(http://beta.visl.sdu.dk/cg3.html).}
\cite{Karlsson-90,Karlsson.Voutilainen.ea-95} then removes
some readings based on syntactic context.

\cite{trosterud2009}

% CGs for Slavic langs

% The preliminary tagging performance is P:,96.1%, R:,99.8% for POS tagging and P:,88.2%, R:,98.1% for complete morphosyntactic tagging.
\cite{peradin12} 

\section{Ambiguity in Russian} \label{ambiguity}

We identify three different types of morphosyntactic ambiguity: 
intraparadigmatic, morphosyntactically incongruent, and morphosyntactically 
congruent. A recent study by Author (2015) found that about 7.5\% of 
morphosyntactic ambiguity in a corpus of Russian resulted in stress placement 
ambiguity. The following examples make use of stress ambiguity to illustrate 
each kind of ambiguity. \emph{Intraparadigmatic} ambiguity refers to homographic 
wordforms belonging to the same lexeme, as shown in \ref{ex:intrahom}. 

\needspace{4\baselineskip} % keeps example all together (no orphan line) 
\ex. Intraparadigmatic homographs \label{ex:intrahom}
\a. \rus{т\'{е}ла} \emph{t\'{e}la} `body.\textsubscript{SG-GEN}' 
    \label{ex:bodySGGEN}
\b. \rus{тел\'{а}} \emph{tel\'{a}} `body.\textsubscript{PL-NOM}' 
    \label{ex:bodyPLNOM}

The remaining two types of ambiguity occur between lexemes. 
\emph{Morphosyntactically incongruent} ambiguity occurs between homographs that 
belong to separate lexemes, and whose morphosyntactic values are different, as 
shown in \ref{ex:MSincongruent}.

\needspace{4\baselineskip} % keeps example all together (no orphan line) 
\ex. Morphosyntactically incongruent homographs \label{ex:MSincongruent}
\a. \rus{н\'{а}шей} \emph{nášej} `our.\textsubscript{F-SG-GEN/DAT/LOC...}'\\
    \rus{наш\'{е}й} \emph{našéj} `sew on.\textsubscript{IMP-2SG}'
\b. \rus{дор\'{о}га} \emph{doróga} `road.\textsubscript{N-F-SG-NOM}'\\
    \rus{дорог\'{а}} \emph{dorogá} `dear.\textsubscript{ADJ-F-SG-PRED}'

\emph{Morphosyntactically congruent} ambiguity occurs between homographs 
that belong to separate lexemes, and whose morphosyntactic values are identical, 
as shown in \ref{ex:MScongruent}. As indicated in Table~\ref{table:ambiguity}, 
this kind of ambiguity is relatively rare, and resolving this ambiguity requires 
the use of technologies such as word sense disambiguation.

\needspace{6\baselineskip} % keeps example all together (no orphan line) 
\ex. Morphosyntactically congruent homographs \label{ex:MScongruent}
\a. \rus{з\'{a}мок} \emph{z\'{a}mok} `castle.\textsubscript{SG-NOM}'\\
	\rus{зам\'{о}к} \emph{zam\'{o}k} `lock.\textsubscript{SG-NOM}'
\b. \rus{з\'{a}мков} \emph{z\'{a}mkov} `castle.\textsubscript{PL-GEN}'\\
	\rus{замк\'{о}в} \emph{zamk\'{o}v} `lock.\textsubscript{PL-GEN}'
\c. ...\\
	...

Table \ref{table:ambiguity} shows the proportional prevalence of each kind of 
ambiguity. Note that these proportions do not sum to 1, since a given token may 
exhibit more than one kind of ambiguity. The first column shows the proportion 
of all tokens in a corpus that have each kind of ambiguity. The second column 
shows what proportion of ambiguous tokens exhibit each kind of ambiguity.

Table~\ref{table:ambiguity} shows that most morphosyntactic ambiguity in 
unrestricted Russian text is rooted in intraparadigmatic and morphosyntactically 
incongruent ambiguity. Detailed part-of-speech tagging with morphosyntactic 
analysis can help disambiguate these forms. Morphosyntactically congruent stress 
ambiguity cannot be disambiguated by means of detailed part-of-speech tagging, 
and since congruent stress ambiguity represents only a small percentage of 
ambiguous wordforms, we leave it to future work.

\begin{table}
  \centering
  \begin{tabular}{l|rr}
    \hline
    \textbf{Type}  & \textbf{all tokens} & \textbf{ambig. tokens} \\
    \hline
    Intraparadigm. & 0.590                   & 0.909   \\
    Incongruent    & 0.277                   & 0.427   \\ 
    Congruent      & 0.120                   & 0.180    \\ 
    \hline
  \end{tabular}
  \caption{Proportional frequency of different types of morphosyntactic ambiguity in unrestricted text}
  \label{table:ambiguity}
\end{table}

% numbers not perfect, e.g. лицо should be 'cong.' but will turn up as 'intra.'

% we should perhaps mention something about systematic ambiguities and tagging guidelines,
% and how we deal with stuffs
% e.g. adj/participle
%      det/pron
%      acc2/nom
%      lexicalised passive / pass

% perhaps mention where our annotation guidelines are (do we mention stuff like один)?

\section{Pipeline}

% FRAN

\subsection{Morphological analyser}
% ROB

The morphological transducer used in this study is described in Author (2015). 
It is primarily based on Zaliznjak's ``Grammatical dictionary of Russian'', 
including the 2001 version's appendix of proper nouns. It also includes approximately CITE Grishina and Lyashevskaya 2008. http://dict.ruslang.ru/gram.php .

Example~\ref{ex:FSToutput} gives some examples of the output.

\ex. \label{ex:FSToutput} 
	\a. \rus{новый}+A+Msc+Inan+Sg+Nom
	\b. \rus{автомат}+N+Msc+Inan+Sg+Nom
	\c. 
% det/prn (e.g. pos... их, я, мой)
% 'over'generation (e.g. all dets get all gen/nbr/case combinations)

\subsection{Disambiguation rules}
%FRAN

The constraint grammar is composed of 299 rules which 

\begin{table}
  \centering
  \begin{tabular}{lrrr}
    \hline
                     & {\sc select} & {\sc remove} & {\sc map} \\
    Safe             &   16         &   34         &  -- \\
    Safe heuristic   &   89         &   76         &  -- \\
    Heuristic        &   26         &   52         &  -- \\
    Syntax labelling & --           & --           & 6 \\ 
    \hline
  \end{tabular}
  \caption{The 299 rules in the grammar are separated into four sections depending
      on rule reliability. }
\end{table}

% The philosophy is that safe rules should represent real constraints in
% the language. Examples might be that a preposition cannot directly preceed a finite verb
% or that prepositional case requires a preceeding preposition. 

% Examples where this might go wrong.

% Safe heuristic rules should represent highly frequent tendencies in the language,
% for example remove a genitive at the beginning of a sentence if it is capitalised
% and there is no verb governing the genitive found to the right. 

% Examples where this might go wrong.

Heuristic rules are those which we do not consider linguistic constraints, but express
preferences, often dealing with overgeneration or overspecification in the morphological
analyser. For example, remove the verbal adverb reading of \rus{такая}, which could be 
the feminine singular nominative of \rus{такой} `such' or the verbal adverb 
of \rus{такать} `say \emph{well}\ldots'.

% Examples where this might go wrong.

Given a large hand-annotated corpus we believe that most of the heuristic rules would be 
better replaced with information learnt from the corpus through stochastic methods. 



\section{Development process}
%FRAN

A common approach taken when writing constraint grammar rules is to 
apply the existing rule set to a new text, write new rules to deal with the 
ambiguities, then apply the rules to a hand-annotated corpus to see
how often the rule disambiguated correctly \cite{voutilainen99}.

Due to the lack of a hand-annotated corpus compatible with our morphological
analyser, we adopted a slightly modified technique. We picked a random text
from the Russian Wikipedia, ran it through the morphological analyser, wrote 
rules, and then ran the rules on the whole Wikipedia corpus. For each rule,
we collected around 100 example applications and checked them. If a rule
selected the appropriate reading in all cases, we included it in the \emph{safe}
rule set, if it removed an appropriate reading in less then three cases, 
then we included it in the \emph{safe heuristic} rule set. Otherwise we either
discarded the rule or included it in the heuristic rule set.

\subsection{Combining with a statistical tagger}

\section{Evaluation}

\subsection{Corpus}

In order to evaluate the grammar we hand-annotated 10,150 words of Russian text
from Wikipedia articles, public domain literature and freely-available news sources. The
annotated texts are available online under the {\sc cc-by-sa} licence.\footnote{\url{http://...}}

Hand-annotation proceeded as follows: The text was first morphologically analysed, 
and then an annotator read through the output of the morphological analyser, commenting
out the readings which were not appropriate in context. This annotated text was then checked
by a second annotator.

We chose our own texts as opposed to using a well-known hand-annotated corpus
such as the Russian National Corpus (RNC) for two main reasons: the first was that the 
RNC is not freely available; the second was that the standards for tokenisation, part-of-speech
and morphological description are different from our morphological analyser.

\subsection{Intrinsic}
%FRAN

\begin{table*}
  \centering
  \begin{tabular}{|l|r|r|r|r|r|}
    \hline
    \textbf{Domain} & \textbf{Tokens} & \textbf{Precision} & \textbf{Recall} & \textbf{F-score} & \textbf{Ambig. solved} \\
    \hline
    Wikipedia       & 7,857      & 0.506        & 0.996    & 0.671 & 44.92\%  \\
    Literature      & 1,652      & 0.473        & 0.984    & 0.638 & 42.95\%  \\
    News            & 642        & 0.471        & 0.990    & 0.638 & 41.60\%  \\
    \hline
    \textbf{Average}& 10,150     & 0.498        &  0.994   & 0.663 & 44.39\% \\
    \hline
  \end{tabular}
  \caption{Results for the test corpora.}
\end{table*}


\begin{table}
  \centering
  \begin{tabular}{|l|r|r|}
    
    \hline
    Error in original        &   & 2 \\
    Missing lexeme           &   & 8  \\          % безбалластный, FALSENEG: Кий<np><ant><m><sg><ins> ['кий<n><m><nn><sg><ins>']
    Partial lexeme           &   & 2  \\          % франко-норманнское, рельс
    Missing analysis         &   &    \\        % 
    Equally valid analysis   &   &    \\   % большой<adj><comp><pred> ['больше<adv>'] (?)
    Correct reading removed  &   & 34   \\ % 
    \hline
                             &   & 46 \\
    \hline
  \end{tabular}
  \caption{Error analysis of false negatives}
\end{table}

% unknown words from test corpus, categorisation

% rule error analysis

%% safe:

% <REMOVE:382>  0       29      0       1
% REMOVE Det IF (1 EOS) ;
% Но, разумеется, никогда нам не исчерпать всего явления, не добраться до конца и начала его.
% postposed determiner (or pronoun?)

% <REMOVE:492>  0       12      0       1
% REMOVE Det IF (0 Det OR Pron) (1C Ne) ;
% Это я знал еще с 46-го года, когда начал писать, а может быть и раньше, - и факт этот не раз поражал меня и ставил меня в недоумение о полезности искусства при таком видимом его бессилии.
% postposed determiner

% <REMOVE:414>	0	0	0	1
% REMOVE A + Short IF (-1C Fin OR Adv OR A) (0C Short OR Adv) ;
% А если удастся, то я прошу только, чтоб схоронили меня, вполне убедясь, что я мертвая, потому что совсем неприятно проснуться в гробу под землею.

% <REMOVE:433>	0	992	0	1
% REMOVE NGDAIP - Acc - Prp - Loc IF (-1C* Pr/V OR Pr/Na BARRIER (*) - Adv - Comp - DetIndecl - ModAcc - ModPrp) ;
% В 1960-х электрифицированные высокоскоростные железные дороги появились в Японии и некоторых других странах.

% <REMOVE:494>	0	60	0	1
% REMOVE Det IF (0 Det OR Pron) (1 Cm LINK 1 CC OR CS) ;
% Но какие, однако же, два разные создания, точно обе с двух разных планет!

%% safe-heuristic:

% <SELECT:718>  0       18      0       1
% SELECT A + $$NGDAIP IF (1C* N + $$NGDAIP BARRIER Punct OR Pr OR Lparen OR NGDAIP - $$NGDAIP LINK -1C* A + $$NGDAIP BARRIER Punct OR Pr OR Lparen OR NGDAIP - $$NGDAIP);
% Движущей силой в поездах являются локомотивы, использующие электричество или производящие собственную мощность, обычно дизельными двигателями.

% <REMOVE:769>  0       57      0       1
% REMOVE IV IF (0 TV OR IV) (1C Acc) (NOT 1 AccAdv) ;
% Их мама внутри дома с кошкой, она смотрит в окно и видит играющих Ваню и Машу.

% <SELECT:692>	0	10	0	2
% SELECT Pron IF (0C Prp) (0 Pron OR Det) (NOT 0 Num) (NOT 1* Prp BARRIER (*) - Adv - DetIndecl) ;
Наземные цели (танки, бронетранспортёры), характерные для штурмовиков и ударных вертолётов, имеют, в большинстве своём, значительно более тяжёлое и прочное бронирование, чем авиационные, что определяет использование бронебойных снарядов.

% <SELECT:835>	0	7	0	1
% SELECT Adv IF (0 Adv LINK 0 CC) (-1C Fin) (1 Modif LINK NOT 1* Fin BARRIER CLB);
% Эта концепция, подкреплённая празднованием в 1982 году 1500-летия Киева, рассматривалась как общепринятая.

% <SELECT:864>	0	13	0	1
% SELECT Nom IF (0C Nom OR Acc) (-1C* Nom BARRIER NGDAIP - Nom - Acc LINK -1C* IV BARRIER NGDAIP - Nom OR TV OR CLB OR Pr) ;
% Если самоубийство не удастся, то пусть соберутся все отпраздновать мое воскресение из мертвых бокалами Клика.

% <REMOVE:542>	0	10	0	1
% REMOVE Adv IF (0C N + Ins OR Adv) (NOT 0 InsAdv) ;
% Он судил организаторов и вдохновителей массового уничтожения граждан Руанды весной 1994 года , среди которых в основном были бывшие чиновники правящего режима.

%% heuristic:

% <REMOVE:917>	0	533	0	2
% REMOVE Dat IF (NOT 0 Prn/Sebe) (NOT 0 Anim OR Cog OR Ant) (NOT 0 Pron) (NOT 1* V/Dat) (NOT -1* V/Dat) (NOT -1* Prep/Dat) (NOT -1C A + Dat) ;
% В связи с этим ортодоксальности стали противопоставлять ересь 
% В противоположность «юбилейной концепции» часть историков и археологов считает, как и прежде, что образование Киева как города проходило в VIII—X веках.

% <SELECT:1065>	0	4	0	1
% SELECT $$NGDAIP IF (0 N + $$NGDAIP) (1 @CNP LINK 1 N + $$NGDAIP) ;
% Однако после войны в Афинах, как и в Греции в целом, начался период ускоренного развития, который длился до 1980-х, когда впервые дали о себе знать проблема перенаселения столицы и проблема транспорта.

% <SELECT:1071>	0	37	0	1
% SELECT $$NGDAIP IF (0 N + $$NGDAIP) (-1 @CNP LINK -1 N + $$NGDAIP) ;
% Образ триединого бога есть сферическая поверхность, а именно: бог-отец в центре, бог-сын — на поверхности и святой дух — в симметричном отношении между центром и описанной вокруг него сферической поверхностью.

% <SELECT:1013>	0	4	0	1
% SELECT Sg IF (0 Prop) (0 Gen) (-1 N) (1 EOS) (NOT -1* Fin + Pl) ;
% Старое здание Афинского университета, расположенное на проспекте Панепистимиу, является одним из самых стильных в городе, наряду с Национальной библиотекой и Академией Афин.



\subsection{Extrinsic}
% ROB accent placement task

\section{Future work}

% ROB
% FRAN
% func analysis
% dep analysis

% better development workflow

\section{Conclusions}


\section*{Acknowledgments}
\textit{Removed for review}

%Do not number the acknowledgment section. Do not include this section
%when submitting your paper for review.

\bibliographystyle{acl}
\bibliography{ruscg}

\end{document}
