%
% File nodalida2015.tex
%
% Contact beata.megyesi@lingfil.uu.se
%
% Based on the instruction file for EACL 2014
% which in turn was based on the instruction files for previous 
% ACL and EACL conferences.


\documentclass[11pt]{article}
\usepackage[T2A,T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian,english]{babel}

\usepackage{times}
\usepackage{latexsym}
\usepackage{fixltx2e} %allows subscripts
%\usepackage{mathptmx}
%\usepackage{txfonts}
\usepackage{url}
\usepackage{graphicx}
\usepackage[small,bf]{caption}
\special{papersize=210mm,297mm} % to avoid having to use "-t a4" with dvips 
%\setlength\titlebox{6.5cm}  % You can expand the title box if you really have to

\usepackage{nodalida2015}

\usepackage{linguex}
\usepackage{needspace}

\newcommand{\rus}[1]{\foreignlanguage{russian}{#1}}

\newcommand{\ft}[1]{\marginpar{\scriptsize F: #1}} % Fran's comments
\newcommand{\rr}[1]{\marginpar{\scriptsize R: #1}} % Rob's comments

\title{A preliminary constraint grammar for Russian}

\author{Francis M. Tyers \\
  HSL-fakultehta, \\
  UiT Norgga árktalaš universitehta, \\
  N-9018 Romsa \\
  {\tt francis.tyers@uit.no} \\\And
  Robert Reynolds \\
  HSL-fakultehta, \\
  UiT Norgga árktalaš universitehta, \\
  N-9018 Romsa \\
  {\tt robert.reynolds@uit.no} \\}

% \author{Author1 \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   {\tt email@domain.com} \\\And
%   Author2 \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   {\tt email@domain.com} \\}
% 
\date{2015}

\begin{document}
\maketitle
\begin{abstract}
 This paper presents preliminary work on a constraint
 grammar based disambiguator for Russian. Russian is
 a Slavic language with a high degree of both in-category
 and out-category homonymy in the inflectional system.
 The pipeline consists of a finite-state morphological
 analyser and constraint grammar. The constraint 
 grammar is tuned to be high recall at the expense of 
 low precision.
\end{abstract}

\section{Introduction}

Our purposes: Processing stressed wordforms and open-source machine translation

\cite{Karlsson-90}

% objectives:
%% make a free/open-source morphology for russian based on Z's dictionary that includes stress

\section{Review of literature}

State-of-the-art morphological analysis in Russian is primarily based on
finite-state technology
\cite{Nozhov-03,Segalovich-03}.\footnote{Machine-learning approaches have also been successfully applied to Russian, most notably by 
\newcite{sharoff08lrec-mocky}.} Almost without exception, all large-scale 
morphological transducers of Russian are based on the
forward-looking \emph{Grammatical Dictionary of Russian} \cite{Zaliznjak-77}.
This dictionary gives fine-grained morphological specifications for more than
100~000 words, including inflectional endings, morphophonemic alternations, 
stress patterns, exceptions, and idiosyncratic collocations.
We base our work on the recently developed [anonymous] morphological transducer, which is also based on Zaliznjak's dictionary (Author, 2015).\footnote{The [anonymous] transducer is implemented using a two-level 
morphology \cite{Koskenniemi-84}, and can be compiled using either {\tt xfst}
\cite{Beesley.Karttunen-03} or {\tt hfst} \cite{hfst-11}} This finite-state transducer (FST) generates all possible 
morphosyntactic readings of each wordform, regardless of its frequency or probability. Because Russian is a relatively highly inflected language, broad coverage is important, but widespread homonymy leads to the generation of many spurious readings, as discussed in Section~\ref{ambiguity} below. Because of this, one of the foundational steps in Russian natural language processing is \rus{снятие омонимии} `morphosyntactic disambiguation'.

% FRAN
% different CGs 
% faroese
% estonian

 -- and our Constraint 
Grammar\footnote{Implemented using vislcg3 constraint grammar parser
(\url{http://beta.visl.sdu.dk/cg3.html}).}
\cite{Karlsson-90,Karlsson.Voutilainen.ea-95} then removes
some readings based on syntactic context.

\cite{trosterud2009}

% CGs for Slavic langs

% The preliminary tagging performance is P:,96.1%, R:,99.8% for POS tagging and P:,88.2%, R:,98.1% for complete morphosyntactic tagging.
\cite{peradin12} 

\section{Ambiguity in Russian} \label{ambiguity}

We identify three different types of morphosyntactic ambiguity: 
intraparadigmatic, morphosyntactically incongruent, and morphosyntactically 
congruent. A recent study by Author (2015) found that about 7.5\% of 
morphosyntactic ambiguity in a corpus of Russian resulted in stress placement 
ambiguity. The following examples make use of stress ambiguity to illustrate 
each kind of ambiguity. \emph{Intraparadigmatic} ambiguity refers to homographic 
wordforms belonging to the same lexeme, as shown in \ref{ex:intrahom}. 

\needspace{4\baselineskip} % keeps example all together (no orphan line) 
\ex. Intraparadigmatic homographs \label{ex:intrahom}
\a. \rus{т\'{е}ла} \emph{t\'{e}la} `body.\textsubscript{SG-GEN}' 
    \label{ex:bodySGGEN}
\b. \rus{тел\'{а}} \emph{tel\'{a}} `body.\textsubscript{PL-NOM}' 
    \label{ex:bodyPLNOM}

The remaining two types of ambiguity occur between lexemes. 
\emph{Morphosyntactically incongruent} ambiguity occurs between homographs that 
belong to separate lexemes, and whose morphosyntactic values are different, as 
shown in \ref{ex:MSincongruent}.

\needspace{4\baselineskip} % keeps example all together (no orphan line) 
\ex. Morphosyntactically incongruent homographs \label{ex:MSincongruent}
\a. \rus{н\'{а}шей} \emph{nášej} `our.\textsubscript{F-SG-GEN/DAT/LOC...}'\\
    \rus{наш\'{е}й} \emph{našéj} `sew on.\textsubscript{IMP-2SG}'
\b. \rus{дор\'{о}га} \emph{doróga} `road.\textsubscript{N-F-SG-NOM}'\\
    \rus{дорог\'{а}} \emph{dorogá} `dear.\textsubscript{ADJ-F-SG-PRED}'

\emph{Morphosyntactically congruent} ambiguity occurs between homographs 
that belong to separate lexemes, and whose morphosyntactic values are identical, 
as shown in \ref{ex:MScongruent}. As indicated in Table~\ref{table:ambiguity}, 
this kind of ambiguity is relatively rare, and resolving this ambiguity requires 
the use of technologies such as word sense disambiguation.

\needspace{6\baselineskip} % keeps example all together (no orphan line) 
\ex. Morphosyntactically congruent homographs \label{ex:MScongruent}
\a. \rus{з\'{a}мок} \emph{z\'{a}mok} `castle.\textsubscript{SG-NOM}'\\
	\rus{зам\'{о}к} \emph{zam\'{o}k} `lock.\textsubscript{SG-NOM}'
\b. \rus{з\'{a}мков} \emph{z\'{a}mkov} `castle.\textsubscript{PL-GEN}'\\
	\rus{замк\'{о}в} \emph{zamk\'{o}v} `lock.\textsubscript{PL-GEN}'
\c. ...\\
	...

Table \ref{table:ambiguity} shows the proportional prevalence of each kind of 
ambiguity. Note that these proportions do not sum to 1, since a given token may 
exhibit more than one kind of ambiguity. The first column shows the proportion 
of all tokens in a corpus that have each kind of ambiguity. The second column 
shows what proportion of ambiguous tokens exhibit each kind of ambiguity.

Table~\ref{table:ambiguity} shows that most morphosyntactic ambiguity in 
unrestricted Russian text is rooted in intraparadigmatic and morphosyntactically 
incongruent ambiguity. Detailed part-of-speech tagging with morphosyntactic 
analysis can help disambiguate these forms. Morphosyntactically congruent stress 
ambiguity cannot be disambiguated by means of detailed part-of-speech tagging, 
and since congruent stress ambiguity represents only a small percentage of 
ambiguous wordforms, we leave it to future work.

\begin{table}
  \centering
  \begin{tabular}{l|rr}
    \hline
    \textbf{Type}  & \textbf{all tokens} & \textbf{ambig. tokens} \\
    \hline
    Intraparadigm. & 0.590                   & 0.909   \\
    Incongruent    & 0.277                   & 0.427   \\ 
    Congruent      & 0.120                   & 0.180    \\ 
    \hline
  \end{tabular}
  \caption{Proportional frequency of different types of morphosyntactic ambiguity in unrestricted text}
  \label{table:ambiguity}
\end{table}

% numbers not perfect, e.g. лицо should be 'cong.' but will turn up as 'intra.'

% we should perhaps mention something about systematic ambiguities and tagging guidelines,
% and how we deal with stuffs
% e.g. adj/participle
%      det/pron
%      acc2/nom
%      lexicalised passive / pass

% perhaps mention where our annotation guidelines are (do we mention stuff like один)?

\section{Pipeline}

% FRAN

\subsection{Morphological analyser}
\label{sec:morph}

The morphological transducer used in this study is described in Author (2015). 
It is primarily based on Zaliznjak's ``Grammatical dictionary of Russian'', 
including the 2001 version's appendix of proper nouns. It also includes approximately CITE Grishina and Lyashevskaya 2008. \url{http://dict.ruslang.ru/gram.php} .

Example~\ref{ex:FSToutput} gives some examples of the output.

\ex. \label{ex:FSToutput} 
	\a. \rus{новый}\texttt{{\small <adj><m><nn><sg><nom>}}
	\b. \rus{автомат}\texttt{{\small <n><m><nn><sg><nom>}}
	\c. 
% det/prn (e.g. pos... их, я, мой)
% 'over'generation (e.g. all dets get all gen/nbr/case combinations)

\subsection{Disambiguation rules}
%FRAN

The constraint grammar is composed of 299 rules which 

\begin{table}
  \centering
  \begin{tabular}{lrrr}
    \hline
                     & {\sc select} & {\sc remove} & {\sc map} \\
    \hline
    Safe             &   16         &   34         &  -- \\
    Safe heuristic   &   89         &   76         &  -- \\
    Heuristic        &   26         &   52         &  -- \\
    Syntax labelling & --           & --           & 6 \\ 
    \hline
  \end{tabular}
  \caption{The 299 rules in the grammar are separated into four sections depending
      on rule reliability. }
\end{table}

The philosophy is that safe rules should represent real constraints in
the language. Examples might be that a preposition cannot directly precede a finite verb
or that prepositional case requires a preceeding preposition. 

% Examples where this might go wrong.

Safe heuristic rules should deal with highly frequent tendencies in the language.
For example remove a genitive at the beginning of a sentence if it is capitalised
and there is no verb governing the genitive found to the right and there is also no
negated verb to the right. This rule relies on the fact that if the genitive is in first 
position in the sentence it cannot modify anything before, and no preposition 
can be governing it.

This kind of rule often relies on completeness of sets, in this case the set of verbs
that can take a genitive complement. 

%It also relies on accurate delimitation of sentence
%boundaries, including rules for dealing with \ldots ellipsis.

% Examples where this might go wrong.

Heuristic rules are those which we do not consider linguistic constraints, but express
preferences, often dealing with overgeneration or overspecification in the morphological
transducer. For example, remove the verbal adverb reading of \rus{такая}, which could be 
the feminine singular nominative of \rus{такой} `such' or the verbal adverb 
of \rus{такать} `say \emph{well}\ldots'.

% Examples where this might go wrong.

Given a large hand-annotated corpus we believe that most of the heuristic rules would be 
better replaced with information learnt from the corpus through stochastic methods. 



\section{Development process}
%FRAN

A common approach taken when writing constraint grammar rules is to 
apply the existing rule set to a new text, write new rules to deal with the 
ambiguities, then apply the rules to a hand-annotated corpus to see
how often the rule disambiguated correctly \cite{voutilainen99}.

Due to the lack of a hand-annotated corpus compatible with our morphological
analyser, we adopted a slightly modified technique. We picked a random text
from the Russian Wikipedia, ran it through the morphological analyser, wrote 
rules, and then ran the rules on the whole Wikipedia corpus. For each rule,
we collected around 100 example applications and checked them. If a rule
selected the appropriate reading in all cases, we included it in the \emph{safe}
rule set, if it removed an appropriate reading in less then three cases, 
then we included it in the \emph{safe heuristic} rule set. Otherwise we either
discarded the rule or included it in the heuristic rule set.

\section{Evaluation}
\label{sec:eval}

\subsection{Corpus}
In order to evaluate the grammar we hand-annotated 10,150 words of Russian text
from Wikipedia articles, public domain literature and freely-available news sources. The
annotated texts are available online under the {\sc cc-by-sa} licence.\footnote{\url{http://...}}

Hand-annotation proceeded as follows: The text was first morphologically analysed, 
and then an annotator read through the output of the morphological analyser, commenting
out the readings which were not appropriate in context. This annotated text was then checked
by a second annotator.

We chose to annotate our own texts as opposed to using a well-known hand-annotated corpus
such as the Russian National Corpus (RNC) for two main reasons: the first was that the 
RNC is not freely available; the second was that the standards for tokenisation, part-of-speech
and morphological description are different from our morphological analyser.

\subsection{Intrinsic}
%FRAN

\begin{table*}
  \centering
  \begin{tabular}{|l|r|r|r|r|r|}
    \hline
    \textbf{Domain} & \textbf{Tokens} & \textbf{Precision} & \textbf{Recall} & \textbf{F-score} & \textbf{Ambig. solved} \\
    \hline
    Wikipedia       & 7,857      & 0.506        & 0.996    & 0.671 & 44.92\%  \\
    Literature      & 1,652      & 0.473        & 0.984    & 0.638 & 42.95\%  \\
    News            & 642        & 0.471        & 0.990    & 0.638 & 41.60\%  \\
    \hline
    \textbf{Average}& 10,150     & 0.498        &  0.994   & 0.663 & 44.39\% \\
    \hline
  \end{tabular}
  \caption{Results for the test corpora.}
  \label{table:results}
\end{table*}


\begin{table}
  \centering
  \begin{tabular}{|l|r|r|}
    
    \hline
    Error in original        &   & 2 \\
    Missing lexeme           &   & 8  \\          % безбалластный, FALSENEG: Кий<np><ant><m><sg><ins> ['кий<n><m><nn><sg><ins>']
    Partial lexeme           &   & 2  \\          % франко-норманнское, рельс
    Missing analysis         &   &    \\        % 
    Equally valid analysis   &   &    \\   % большой<adj><comp><pred> ['больше<adv>'] (?)
    Correct reading removed  &   & 34   \\ % 
    \hline
                             &   & 46 \\
    \hline
  \end{tabular}
  \caption{Error analysis of false negatives}
\end{table}

% unknown words from test corpus, categorisation

% rule error analysis

\begin{description}
  \item[ Bad linguistics:] In some cases a rule did not take into account grammatical possibilities 
    in the language. e.g. Two simple rules such as 
    \begin{itemize}
      \item \texttt{REMOVE Det IF (0 Det OR Pron) (1C Ne) ;}
      \item \texttt{REMOVE Det IF (0 Det OR Pron) (1 Cm LINK 1 CC OR CS) ;}
    \end{itemize}
    did not take into account the possibility of having a postposed determiner as in
    \begin{itemize}
      \item \ldots \rus{а может быть и раньше, и факт этот не раз поражал меня} \ldots
      \item \ldots and maybe even earlier, and fact \textbf{this} not once surprised me \ldots
    \end{itemize}
    or a interposed parenthetical as in
    \begin{itemize}
      \item \rus{Но какие, однако же, два разные создания, точно обе с двух разных планет!}
      \item But what, \textbf{exactly} , two different creatures, just both from two different planets!
    \end{itemize}
  \item[ Bad rule:] In some cases a rule was simply incorrectly specified. For example, the 
    following rule was designed to solve the ambiguity between short-form neuter adjectives and 
    adverbs
   \begin{itemize}
     \item \texttt{REMOVE A + Short IF (-1C Fin OR Adv OR A) (0C Short OR Adv) ;}
   \end{itemize}
   However there is no reason why we should prefer an adverb over an adjective after an adverb, 
   \begin{itemize}
     \item \ldots \rus{потому что совсем неприятно проснуться в гробу под землею.}
     \item \ldots because [it is] really \textbf{unpleasant} to wake up in a coffin under the ground.
   \end{itemize}
  \item[ Incomplete barrier:] xxx 
   \begin{itemize} 
     \item \texttt{REMOVE NGDAIP - Acc - Prp - Loc IF (-1C* Pr/V OR Pr/Na BARRIER (*) - Adv - Comp - DetIndecl - ModAcc - ModPrp) ;}
   \end{itemize}
   here the rule removes the nominative reading of the adjective to leave the accusative reading because the preposition \rus{в} `in'
   is found preceeding. 
   \begin{itemize}
     \item \rus{В 1960-х электрифицированные высокоскоростные железные дороги появились в Японии и некоторых других странах.}
     \item In the 1960's \textbf{electrified} high-speed railways appeared in Japan and some other countries.
   \end{itemize} 
  \item[ Incomplete set:] In some cases the rule was a good generalisation, but made use of a set
    which was incomplete. For example:
   \begin{itemize}
     \item \texttt{REMOVE Dat IF (NOT 0 Prn/Sebe) (NOT 0 Anim OR Cog OR Ant) (NOT 0 Pron) (NOT 1* V/Dat) (NOT -1* V/Dat) (NOT -1* Prep/Dat) (NOT -1C A + Dat) ;}
   \end{itemize} 
   the set \texttt{V/Dat} does not contain the verb \rus{противопоставлять} `opposed to' which takes 
   a dative argument.
   \begin{itemize}
     \item \rus{В связи с этим ортодоксальности стали противопоставлять ересь.}
     \item In connection with this \textbf{orthodoxy} was opposed to heresy. 
   \end{itemize}
  \item[ Rule interaction:] The strong accusative rule below causes incorrect behaviour in the rule to remove transitivity readings
  \begin{itemize}
     \item \texttt{REMOVE TV - Pass IF (NOT 1* Acc) (NOT -1* Acc) ;}
     \item \texttt{REMOVE Acc IF (-1C Fin + IV) (NOT 0 AccAdv) ;}
  \end{itemize}
  Consider the following example where \rus{может} `can' is tagged as intransitive, the second rule fires removing 
  the accusative reading of \rus{его} `him', and thus given the lack of accusative reading, \rus{найти} `find'
  is disambiguated as intransitive instead of transitive.
  \begin{itemize}
    \item \rus{Она смотрит везде, но не может его найти.}
    \item She looks around, but she cannot \textbf{find him}.
  \end{itemize}
  \item[ Difficult linguistics:] Dealing with participles with arguments is challenging in the case that the arguments 
    of the participle share the same government as the main verb.
  \begin{itemize}
    \item \texttt{REMOVE IV IF (0 TV OR IV) (1C Acc) (NOT 1 AccAdv) ;}
  \end{itemize}
    Here \rus{Ваню и Машу} `Vanja and Maša' are the object of \rus{видит} `sees' and not \rus{играющих} `playing', although
    both verbs can take accusative object.
  \begin{itemize}
    \item \rus{Их мама внутри дома с кошкой, она смотрит в окно и видит играющих Ваню и Машу.}
    \item Their mother is inside the house with the cat, she looks through the window and sees Vanja and Maša \textbf{playing}.
  \end{itemize}
    This kind of error would ideally be resolved with semantic knowledge. 
\end{description}

%% safe:

% <REMOVE:382>  0       29      0       1
% REMOVE Det IF (1 EOS) ;
% Но, разумеется, никогда нам не исчерпать всего явления, не добраться до конца и начала его.
%+ postposed determiner (or pronoun?)

% <REMOVE:492>  0       12      0       1
% REMOVE Det IF (0 Det OR Pron) (1C Ne) ;
% Это я знал еще с 46-го года, когда начал писать, а может быть и раньше, - и факт этот не раз поражал меня и ставил меня в недоумение о полезности искусства при таком видимом его бессилии.
%+ postposed determiner (факт этот)

% <REMOVE:414>	0	0	0	1
% REMOVE A + Short IF (-1C Fin OR Adv OR A) (0C Short OR Adv) ;
% А если удастся, то я прошу только, чтоб схоронили меня, вполне убедясь, что я мертвая, потому что совсем неприятно проснуться в гробу под землею.
%+ bad rule. adverb (maybe adj too) does not make sense here 

% <REMOVE:433>	0	992	0	1
% REMOVE NGDAIP - Acc - Prp - Loc IF (-1C* Pr/V OR Pr/Na BARRIER (*) - Adv - Comp - DetIndecl - ModAcc - ModPrp) ;
% В 1960-х электрифицированные высокоскоростные железные дороги появились в Японии и некоторых других странах.
%+ incomplete barrier (ordinal in another case)

% <REMOVE:494>	0	60	0	1
% REMOVE Det IF (0 Det OR Pron) (1 Cm LINK 1 CC OR CS) ;
% Но какие, однако же, два разные создания, точно обе с двух разных планет!
%+ parentheticals

%% safe-heuristic:

% <SELECT:718>  0       18      0       1
% SELECT A + $$NGDAIP IF (1C* N + $$NGDAIP BARRIER Punct OR Pr OR Lparen OR NGDAIP - $$NGDAIP LINK -1C* A + $$NGDAIP BARRIER Punct OR Pr OR Lparen OR NGDAIP - $$NGDAIP);
% Движущей силой в поездах являются локомотивы, использующие электричество или производящие собственную мощность, обычно дизельными двигателями.
%+ missing unification on number, rule too loose.

% <REMOVE:769>  0       57      0       1
% REMOVE IV IF (0 TV OR IV) (1C Acc) (NOT 1 AccAdv) ;
% Их мама внутри дома с кошкой, она смотрит в окно и видит играющих Ваню и Машу.
%+ participle is intransitive, because it is modifying Vanju and Mašu, but they are object of видит so look like object of играющих. both syntactically valid, but semantics would tell you that you can't play people.

% <SELECT:692>	0	10	0	2
% SELECT Pron IF (0C Prp) (0 Pron OR Det) (NOT 0 Num) (NOT 1* Prp BARRIER (*) - Adv - DetIndecl) ;
% Наземные цели (танки, бронетранспортёры), характерные для штурмовиков и ударных вертолётов, имеют, в большинстве своём, значительно более тяжёлое и прочное бронирование, чем авиационные, что определяет использование бронебойных снарядов.
%+ postposed determiner своём

% <SELECT:864>	0	13	0	1
% SELECT Nom IF (0C Nom OR Acc) (-1C* Nom BARRIER NGDAIP - Nom - Acc LINK -1C* IV BARRIER NGDAIP - Nom OR TV OR CLB OR Pr) ;
% Если самоубийство не удастся, то пусть соберутся все отпраздновать мое воскресение из мертвых бокалами Клика.
% [ only IV ] (anything not nom) [ only nom ] (any case but nom/acc) [nom or acc]
%+ bad rule

% <REMOVE:784>	0	67	0	2
% REMOVE Acc IF (-1C Fin + IV) (NOT 0 AccAdv) ;
% Я именно заметил ему перед этим, что я, чуть не сорок лет знающий "Горе от ума", только в этом году понял как следует один из самых ярких типов этой комедии, Молчалина, и понял именно, когда он же, то есть этот самый писатель, с которым я говорил, разъяснил мне Молчалина, вдруг выведя его в одном из своих сатирических очерков.
%+ parenthetical (как следует)
%! Было установлено, что после того, как 6 апреля 1994 года в авиакатастрофе погиб президент Хабиаримана, Багосора полностью захватил контроль над политической и военной ситуацией в стране, следовательно несёт ответственность за произошедшие затем события .
%! нести = TV here, but IV ?


% <REMOVE:656>	0	16	0	3
% REMOVE TV - Pass IF (NOT 1* Acc) (NOT -1* Acc) ;
% Она ничего не видит, она считает.
% Люди никогда не получают ответа, когда говорят с собаками!
% Она смотрит везде, но не может его найти.
%+ genitive object

%      REMOVE Acc IF (-1C Fin + IV) (NOT 0 AccAdv) ;
%      bad interaction with auxiliary verb rule, we remove the acc reading on его

%% heuristic:

% <REMOVE:917>	0	533	0	2
% REMOVE Dat IF (NOT 0 Prn/Sebe) (NOT 0 Anim OR Cog OR Ant) (NOT 0 Pron) (NOT 1* V/Dat) (NOT -1* V/Dat) (NOT -1* Prep/Dat) (NOT -1C A + Dat) ;
% В связи с этим ортодоксальности стали противопоставлять ересь 
%+ incomplete set (e.g. стали should appear in V/Dat)
% В противоположность «юбилейной концепции» часть историков и археологов считает, как и прежде, что образование Киева как города проходило в VIII—X веках.
%+ противоположность takes dative (против-) 

% <REMOVE:954>	0	272	0	7
% REMOVE Adv/I IF (NOT -1* Adv/Ješë OR Jest OR Rel OR No BARRIER (*) - Adv) (NOT -1* CC BARRIER (*) - Adv) ;
% А знаете ли вы, - вдруг сказал мне мой собеседник, видимо давно уже и глубоко пораженный своей идеей, - знаете ли, что, что бы вы ни написали, что бы ни вывели, что бы ни отметили в художественном произведении, - никогда вы не сравняетесь с действительностью.
% Действительность тотчас же представит вам в этом же роде такой фазис какой вы и еще и не предлагали и превышающий все, что могло создать ваше собственное наблюдение и воображение!
% Действительность тотчас же представит вам в этом же роде такой фазис какой вы и еще и не предлагали и превышающий все, что могло создать ваше собственное наблюдение и воображение!
% Это я знал еще с 46-го года, когда начал писать, а может быть и раньше, - и факт этот не раз поражал меня и ставил меня в недоумение о полезности искусства при таком видимом его бессилии.
% Но ведь в том-то и весь вопрос: чей глаз и кто в силах? 
% Вот эта-то смерть и напомнила мне о сообщенном мне еще летом самоубийстве дочери эмигранта.
% Зачастую и после убийств над телами жертв совершали издевательства — разрубали их на куски и т. д. 
%+ this is a complete mess, in certain genres, и is much more frequent as an adverb
% probably needs collocation info

% <SELECT:1065>	0	4	0	1
% SELECT $$NGDAIP IF (0 N + $$NGDAIP) (1 @CNP LINK 1 N + $$NGDAIP) ;
% Однако после войны в Афинах, как и в Греции в целом, начался период ускоренного развития, который длился до 1980-х, когда впервые дали о себе знать проблема перенаселения столицы и проблема транспорта.
%+ doesn't take into account genitive modifiers

% <SELECT:1071>	0	37	0	1
% SELECT $$NGDAIP IF (0 N + $$NGDAIP) (-1 @CNP LINK -1 N + $$NGDAIP) ;
% Образ триединого бога есть сферическая поверхность, а именно: бог-отец в центре, бог-сын — на поверхности и святой дух — в симметричном отношении между центром и описанной вокруг него сферической поверхностью.
%+ @CNP should be @CVP because of the тире

% <SELECT:1013>	0	4	0	1
% SELECT Sg IF (0 Prop) (0 Gen) (-1 N) (1 EOS) (NOT -1* Fin + Pl) ;
% Старое здание Афинского университета, расположенное на проспекте Панепистимиу, является одним из самых стильных в городе, наряду с Национальной библиотекой и Академией Афин.
%+ massive hack, not linguistically motivated
%+ could be improved by only applying to ant/pat


\subsection{Extrinsic}
% ROB accent placement task

\subsection{Combining with a statistical tagger}

Given that just over half of all ambiguity remains after running our preliminary constraint
grammar and that for many applications unambiguous output is necessary, we decided to 
experiment with combining the constraint grammar with a statistical tagger to resolve remaining
ambiguity. 

We follow the voting method described by \newcite{hulden12}. We used the freely available
\texttt{hunpos} part-of-speech tagger \cite{halacsy07}. We performed 10-fold
cross validation using our evaluation corpus, taking 10\% for testing and 90\% for training, and
experimented with three configurations:

\begin{itemize}
  \item \texttt{HMM}: the \texttt{hunpos} part-of-speech tagger with its default options
  \item \texttt{HMM+Morph}: as with \texttt{HMM} but incorporating the output of our 
    morphological analyser (see section~\ref{sec:morph}) as a full form lexicon.
  \item \texttt{HMM+Morph+CG}: we submitted the output from \texttt{HMM+Morph} and the 
    constraint grammar to a voting procedure, whereby if the constraint grammar left
    one valid reading, we chose that, otherwise if the constraint grammar left a word
    with more than one reading, we chose the result from the \texttt{HMM+Morph} tagger.
\end{itemize}

As can be seen from Figure~\ref{fig:curve}, incorporating the constraint grammar 
improves the performance of the HMM tagger, an improvement of nearly 5\% in accuracy,
similar to that reported by \newcite{hulden12} for the same amount of training data. Our 
constraint grammar also has a much lower precision as a result of the ambiguity remaining
in the output.

Note that the final accuracy is below the state of the art for Russian, however the state of
the art employs unavailable training corpora of over five million tokens. 

\begin{figure}
  \centering
  \includegraphics[width=0.45\textwidth]{graphics/learning-curve.pdf}
  \caption{Learning curve for three taggers, \texttt{hunpos} with no lexicon, 
    \texttt{hunpos} with a lexicon, and \texttt{hunpos} with a lexicon and the 
    Russian constraint grammar in a voting set up.}
  \label{fig:curve}
\end{figure}


\section{Future work}

% ROB
% FRAN
% func analysis
% dep analysis

% better development workflow

% proof-of-concept for russian, but russian has loads of tagged corpora, for other langs, e.g. sorbian or belarusian 
% a CG+hmm could be much faster than tagging hundreds of thousands of words of text.

\section{Conclusions}


\section*{Acknowledgments}
\textit{Removed for review}

%Do not number the acknowledgment section. Do not include this section
%when submitting your paper for review.

\bibliographystyle{acl}
\bibliography{ruscg}

\end{document}
